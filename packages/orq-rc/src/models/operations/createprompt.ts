/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { remap as remap$ } from "../../lib/primitives.js";
import { safeParse } from "../../lib/schemas.js";
import { ClosedEnum } from "../../types/enums.js";
import { Result as SafeParseResult } from "../../types/fp.js";
import * as components from "../components/index.js";
import { SDKValidationError } from "../errors/sdkvalidationerror.js";

export const UseCases = {
  AgentsSimulations: "Agents simulations",
  Agents: "Agents",
  APIInteraction: "API interaction",
  AutonomousAgents: "Autonomous Agents",
  Chatbots: "Chatbots",
  Classification: "Classification",
  CodeUnderstanding: "Code understanding",
  CodeWriting: "Code writing",
  Conversation: "Conversation",
  DocumentsQA: "Documents QA",
  Evaluation: "Evaluation",
  Extraction: "Extraction",
  MultiModal: "Multi-modal",
  SelfChecking: "Self-checking",
  SentimentAnalysis: "Sentiment analysis",
  Sql: "SQL",
  Summarization: "Summarization",
  Tagging: "Tagging",
  TranslationDocument: "Translation (document)",
  TranslationSentences: "Translation (sentences)",
} as const;
export type UseCases = ClosedEnum<typeof UseCases>;

/**
 * The language that the prompt is written in. Use this field to categorize the prompt for your own purpose
 */
export const CreatePromptLanguage = {
  Chinese: "Chinese",
  Dutch: "Dutch",
  English: "English",
  French: "French",
  German: "German",
  Russian: "Russian",
  Spanish: "Spanish",
} as const;
/**
 * The language that the prompt is written in. Use this field to categorize the prompt for your own purpose
 */
export type CreatePromptLanguage = ClosedEnum<typeof CreatePromptLanguage>;

export type CreatePromptMetadata = {
  /**
   * A list of use cases that the prompt is meant to be used for. Use this field to categorize the prompt for your own purpose
   */
  useCases?: Array<UseCases> | undefined;
  /**
   * The language that the prompt is written in. Use this field to categorize the prompt for your own purpose
   */
  language?: CreatePromptLanguage | null | undefined;
};

export type CreatePromptContentPromptsRequest2 =
  components.TextContentPartSchema;

/**
 * The contents of the tool message.
 */
export type CreatePromptMessagesPromptsRequestRequestBodyContent =
  | string
  | Array<components.TextContentPartSchema>;

/**
 * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
 */
export const CreatePromptMessagesPromptsType = {
  Ephemeral: "ephemeral",
} as const;
/**
 * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
 */
export type CreatePromptMessagesPromptsType = ClosedEnum<
  typeof CreatePromptMessagesPromptsType
>;

/**
 * The time-to-live for the cache control breakpoint. This may be one of the following values:
 *
 * @remarks
 *
 * - `5m`: 5 minutes
 * - `1h`: 1 hour
 *
 * Defaults to `5m`. Only supported by `Anthropic` Claude models.
 */
export const CreatePromptMessagesTtl = {
  Fivem: "5m",
  Oneh: "1h",
} as const;
/**
 * The time-to-live for the cache control breakpoint. This may be one of the following values:
 *
 * @remarks
 *
 * - `5m`: 5 minutes
 * - `1h`: 1 hour
 *
 * Defaults to `5m`. Only supported by `Anthropic` Claude models.
 */
export type CreatePromptMessagesTtl = ClosedEnum<
  typeof CreatePromptMessagesTtl
>;

export type CreatePromptMessagesCacheControl = {
  /**
   * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
   */
  type: CreatePromptMessagesPromptsType;
  /**
   * The time-to-live for the cache control breakpoint. This may be one of the following values:
   *
   * @remarks
   *
   * - `5m`: 5 minutes
   * - `1h`: 1 hour
   *
   * Defaults to `5m`. Only supported by `Anthropic` Claude models.
   */
  ttl?: CreatePromptMessagesTtl | undefined;
};

export type CreatePromptMessagesToolMessage = {
  /**
   * The role of the messages author, in this case tool.
   */
  role: "tool";
  /**
   * The contents of the tool message.
   */
  content: string | Array<components.TextContentPartSchema>;
  /**
   * Tool call that this message is responding to.
   */
  toolCallId: string | null;
  cacheControl?: CreatePromptMessagesCacheControl | undefined;
};

export type CreatePromptContentPrompts2 =
  | (components.TextContentPartSchema & { type: "text" })
  | components.RefusalPartSchema
  | components.ReasoningPartSchema
  | components.RedactedReasoningPartSchema;

/**
 * The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
 */
export type CreatePromptMessagesPromptsRequestContent =
  | string
  | Array<
    | (components.TextContentPartSchema & { type: "text" })
    | components.RefusalPartSchema
    | components.ReasoningPartSchema
    | components.RedactedReasoningPartSchema
  >;

/**
 * Data about a previous audio response from the model.
 */
export type CreatePromptMessagesAudio = {
  /**
   * Unique identifier for a previous audio response from the model.
   */
  id: string;
};

/**
 * The type of the tool. Currently, only `function` is supported.
 */
export const CreatePromptMessagesType = {
  Function: "function",
} as const;
/**
 * The type of the tool. Currently, only `function` is supported.
 */
export type CreatePromptMessagesType = ClosedEnum<
  typeof CreatePromptMessagesType
>;

export type CreatePromptMessagesFunction = {
  /**
   * The name of the function to call.
   */
  name?: string | undefined;
  /**
   * The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
   */
  arguments?: string | undefined;
};

export type CreatePromptMessagesToolCalls = {
  /**
   * The ID of the tool call.
   */
  id: string;
  /**
   * The type of the tool. Currently, only `function` is supported.
   */
  type: CreatePromptMessagesType;
  function: CreatePromptMessagesFunction;
  /**
   * Encrypted representation of the model internal reasoning state during function calling. Required by Gemini 3 models when continuing a conversation after a tool call.
   */
  thoughtSignature?: string | undefined;
};

export type CreatePromptMessagesAssistantMessage = {
  /**
   * The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
   */
  content?:
    | string
    | Array<
      | (components.TextContentPartSchema & { type: "text" })
      | components.RefusalPartSchema
      | components.ReasoningPartSchema
      | components.RedactedReasoningPartSchema
    >
    | null
    | undefined;
  /**
   * The refusal message by the assistant.
   */
  refusal?: string | null | undefined;
  /**
   * The role of the messages author, in this case `assistant`.
   */
  role: "assistant";
  /**
   * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
   */
  name?: string | undefined;
  /**
   * Data about a previous audio response from the model.
   */
  audio?: CreatePromptMessagesAudio | null | undefined;
  /**
   * The tool calls generated by the model, such as function calls.
   */
  toolCalls?: Array<CreatePromptMessagesToolCalls> | undefined;
};

/**
 * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
 */
export const CreatePrompt2PromptsType = {
  Ephemeral: "ephemeral",
} as const;
/**
 * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
 */
export type CreatePrompt2PromptsType = ClosedEnum<
  typeof CreatePrompt2PromptsType
>;

/**
 * The time-to-live for the cache control breakpoint. This may be one of the following values:
 *
 * @remarks
 *
 * - `5m`: 5 minutes
 * - `1h`: 1 hour
 *
 * Defaults to `5m`. Only supported by `Anthropic` Claude models.
 */
export const CreatePrompt2Ttl = {
  Fivem: "5m",
  Oneh: "1h",
} as const;
/**
 * The time-to-live for the cache control breakpoint. This may be one of the following values:
 *
 * @remarks
 *
 * - `5m`: 5 minutes
 * - `1h`: 1 hour
 *
 * Defaults to `5m`. Only supported by `Anthropic` Claude models.
 */
export type CreatePrompt2Ttl = ClosedEnum<typeof CreatePrompt2Ttl>;

export type CreatePrompt2CacheControl = {
  /**
   * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
   */
  type: CreatePrompt2PromptsType;
  /**
   * The time-to-live for the cache control breakpoint. This may be one of the following values:
   *
   * @remarks
   *
   * - `5m`: 5 minutes
   * - `1h`: 1 hour
   *
   * Defaults to `5m`. Only supported by `Anthropic` Claude models.
   */
  ttl?: CreatePrompt2Ttl | undefined;
};

export type CreatePrompt24 = {
  /**
   * The type of the content part. Always `file`.
   */
  type: "file";
  cacheControl?: CreatePrompt2CacheControl | undefined;
  /**
   * File data for the content part. Must contain either file_data or uri, but not both.
   */
  file: components.FileContentPartSchema;
};

export type CreatePromptContent2 =
  | (components.TextContentPartSchema & { type: "text" })
  | components.ImageContentPartSchema
  | components.AudioContentPartSchema
  | CreatePrompt24;

/**
 * The contents of the user message.
 */
export type CreatePromptMessagesPromptsContent =
  | string
  | Array<
    | (components.TextContentPartSchema & { type: "text" })
    | components.ImageContentPartSchema
    | components.AudioContentPartSchema
    | CreatePrompt24
  >;

export type CreatePromptMessagesUserMessage = {
  /**
   * The role of the messages author, in this case `user`.
   */
  role: "user";
  /**
   * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
   */
  name?: string | undefined;
  /**
   * The contents of the user message.
   */
  content:
    | string
    | Array<
      | (components.TextContentPartSchema & { type: "text" })
      | components.ImageContentPartSchema
      | components.AudioContentPartSchema
      | CreatePrompt24
    >;
};

/**
 * The contents of the system message.
 */
export type CreatePromptMessagesContent =
  | string
  | Array<components.TextContentPartSchema>;

/**
 * Developer-provided instructions that the model should follow, regardless of messages sent by the user.
 */
export type CreatePromptMessagesSystemMessage = {
  /**
   * The role of the messages author, in this case `system`.
   */
  role: "system";
  /**
   * The contents of the system message.
   */
  content: string | Array<components.TextContentPartSchema>;
  /**
   * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
   */
  name?: string | undefined;
};

export type CreatePromptMessages =
  | CreatePromptMessagesSystemMessage
  | CreatePromptMessagesUserMessage
  | CreatePromptMessagesAssistantMessage
  | CreatePromptMessagesToolMessage;

/**
 * The voice the model uses to respond. Supported voices are alloy, echo, fable, onyx, nova, and shimmer.
 */
export const CreatePromptVoice = {
  Alloy: "alloy",
  Echo: "echo",
  Fable: "fable",
  Onyx: "onyx",
  Nova: "nova",
  Shimmer: "shimmer",
} as const;
/**
 * The voice the model uses to respond. Supported voices are alloy, echo, fable, onyx, nova, and shimmer.
 */
export type CreatePromptVoice = ClosedEnum<typeof CreatePromptVoice>;

/**
 * Specifies the output audio format. Must be one of wav, mp3, flac, opus, or pcm16.
 */
export const CreatePromptFormat = {
  Wav: "wav",
  Mp3: "mp3",
  Flac: "flac",
  Opus: "opus",
  Pcm16: "pcm16",
} as const;
/**
 * Specifies the output audio format. Must be one of wav, mp3, flac, opus, or pcm16.
 */
export type CreatePromptFormat = ClosedEnum<typeof CreatePromptFormat>;

/**
 * Parameters for audio output. Required when audio output is requested with modalities: ["audio"]. Learn more.
 */
export type CreatePromptAudio = {
  /**
   * The voice the model uses to respond. Supported voices are alloy, echo, fable, onyx, nova, and shimmer.
   */
  voice: CreatePromptVoice;
  /**
   * Specifies the output audio format. Must be one of wav, mp3, flac, opus, or pcm16.
   */
  format: CreatePromptFormat;
};

export type CreatePromptResponseFormatPromptsJsonSchema = {
  /**
   * A description of what the response format is for, used by the model to determine how to respond in the format.
   */
  description?: string | undefined;
  /**
   * The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
   */
  name: string;
  /**
   * The schema for the response format, described as a JSON Schema object.
   */
  schema?: any | undefined;
  /**
   * Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true.
   */
  strict?: boolean | undefined;
};

/**
 * @remarks
 *
 * JSON Schema response format. Used to generate structured JSON responses
 */
export type CreatePromptResponseFormatJSONSchema = {
  type: "json_schema";
  jsonSchema: CreatePromptResponseFormatPromptsJsonSchema;
};

/**
 * @remarks
 *
 * JSON object response format. An older method of generating JSON responses. Using `json_schema` is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.
 */
export type CreatePromptResponseFormatJSONObject = {
  type: "json_object";
};

/**
 * @remarks
 *
 * Default response format. Used to generate text responses
 */
export type CreatePromptResponseFormatText = {
  type: "text";
};

/**
 * An object specifying the format that the model must output
 */
export type CreatePromptResponseFormat =
  | CreatePromptResponseFormatText
  | CreatePromptResponseFormatJSONObject
  | CreatePromptResponseFormatJSONSchema;

/**
 * Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
 *
 * @remarks
 *
 * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool calls are supported for all reasoning values in gpt-5.1.
 * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not support `none`.
 * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
 * - `xhigh` is currently only supported for `gpt-5.1-codex-max`.
 *
 * Any of "none", "minimal", "low", "medium", "high", "xhigh".
 */
export const CreatePromptReasoningEffort = {
  None: "none",
  Minimal: "minimal",
  Low: "low",
  Medium: "medium",
  High: "high",
  Xhigh: "xhigh",
} as const;
/**
 * Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
 *
 * @remarks
 *
 * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool calls are supported for all reasoning values in gpt-5.1.
 * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not support `none`.
 * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
 * - `xhigh` is currently only supported for `gpt-5.1-codex-max`.
 *
 * Any of "none", "minimal", "low", "medium", "high", "xhigh".
 */
export type CreatePromptReasoningEffort = ClosedEnum<
  typeof CreatePromptReasoningEffort
>;

/**
 * Up to 4 sequences where the API will stop generating further tokens.
 */
export type CreatePromptStop = string | Array<string>;

/**
 * Options for streaming response. Only set this when you set stream: true.
 */
export type CreatePromptStreamOptions = {
  /**
   * If set, an additional chunk will be streamed before the data: [DONE] message. The usage field on this chunk shows the token usage statistics for the entire request, and the choices field will always be an empty array. All other chunks will also include a usage field, but with a null value.
   */
  includeUsage?: boolean | undefined;
};

export type CreatePromptThinking =
  | components.ThinkingConfigDisabledSchema
  | components.ThinkingConfigEnabledSchema;

/**
 * The type of the tool. Currently, only function is supported.
 */
export const CreatePromptToolChoiceType = {
  Function: "function",
} as const;
/**
 * The type of the tool. Currently, only function is supported.
 */
export type CreatePromptToolChoiceType = ClosedEnum<
  typeof CreatePromptToolChoiceType
>;

export type CreatePromptToolChoiceFunction = {
  /**
   * The name of the function to call.
   */
  name: string;
};

export type CreatePromptToolChoice2 = {
  /**
   * The type of the tool. Currently, only function is supported.
   */
  type?: CreatePromptToolChoiceType | undefined;
  function: CreatePromptToolChoiceFunction;
};

export const CreatePromptToolChoice1 = {
  None: "none",
  Auto: "auto",
  Required: "required",
} as const;
export type CreatePromptToolChoice1 = ClosedEnum<
  typeof CreatePromptToolChoice1
>;

/**
 * Controls which (if any) tool is called by the model.
 */
export type CreatePromptToolChoice =
  | CreatePromptToolChoice2
  | CreatePromptToolChoice1;

export const CreatePromptModalities = {
  Text: "text",
  Audio: "audio",
} as const;
export type CreatePromptModalities = ClosedEnum<typeof CreatePromptModalities>;

/**
 * The key of the guardrail.
 */
export const CreatePromptId1 = {
  OrqPiiDetection: "orq_pii_detection",
  OrqSexualModeration: "orq_sexual_moderation",
  OrqHarmfulModeration: "orq_harmful_moderation",
} as const;
/**
 * The key of the guardrail.
 */
export type CreatePromptId1 = ClosedEnum<typeof CreatePromptId1>;

export type CreatePromptId = CreatePromptId1 | string;

/**
 * Determines whether the guardrail runs on the input (user message) or output (model response).
 */
export const CreatePromptExecuteOn = {
  Input: "input",
  Output: "output",
} as const;
/**
 * Determines whether the guardrail runs on the input (user message) or output (model response).
 */
export type CreatePromptExecuteOn = ClosedEnum<typeof CreatePromptExecuteOn>;

export type CreatePromptGuardrails = {
  id: CreatePromptId1 | string;
  /**
   * Determines whether the guardrail runs on the input (user message) or output (model response).
   */
  executeOn: CreatePromptExecuteOn;
};

export type CreatePromptFallbacks = {
  /**
   * Fallback model identifier
   */
  model: string;
};

/**
 * Retry configuration for the request
 */
export type CreatePromptRetry = {
  /**
   * Number of retry attempts (1-5)
   */
  count?: number | undefined;
  /**
   * HTTP status codes that trigger retry logic
   */
  onCodes?: Array<number> | undefined;
};

export const CreatePromptType = {
  ExactMatch: "exact_match",
} as const;
export type CreatePromptType = ClosedEnum<typeof CreatePromptType>;

/**
 * Cache configuration for the request.
 */
export type CreatePromptCache = {
  /**
   * Time to live for cached responses in seconds. Maximum 259200 seconds (3 days).
   */
  ttl?: number | undefined;
  type: CreatePromptType;
};

export const CreatePromptLoadBalancerType = {
  WeightBased: "weight_based",
} as const;
export type CreatePromptLoadBalancerType = ClosedEnum<
  typeof CreatePromptLoadBalancerType
>;

export type CreatePromptLoadBalancer1 = {
  type: CreatePromptLoadBalancerType;
  /**
   * Model identifier for load balancing
   */
  model: string;
  /**
   * Weight assigned to this model for load balancing
   */
  weight?: number | undefined;
};

export type CreatePromptLoadBalancer = CreatePromptLoadBalancer1;

/**
 * Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured.
 */
export type CreatePromptTimeout = {
  /**
   * Timeout value in milliseconds
   */
  callTimeout: number;
};

/**
 * Prompt configuration with model and messages.
 */
export type PromptInput = {
  /**
   * Array of messages that make up the conversation. Each message has a role (system, user, assistant, or tool) and content.
   */
  messages: Array<
    | CreatePromptMessagesSystemMessage
    | CreatePromptMessagesUserMessage
    | CreatePromptMessagesAssistantMessage
    | CreatePromptMessagesToolMessage
  >;
  /**
   * Model ID used to generate the response, like `openai/gpt-4o` or `anthropic/claude-3-5-sonnet-20241022`. For private models, use format: `{workspaceKey}@{provider}/{model}`. The full list of models can be found at https://docs.orq.ai/docs/ai-gateway-supported-models. Only chat models are supported.
   */
  model?: string | undefined;
  /**
   * Parameters for audio output. Required when audio output is requested with modalities: ["audio"]. Learn more.
   */
  audio?: CreatePromptAudio | null | undefined;
  /**
   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
   */
  frequencyPenalty?: number | null | undefined;
  /**
   * `[Deprecated]`. The maximum number of tokens that can be generated in the chat completion. This value can be used to control costs for text generated via API.
   *
   * @remarks
   *
   *  This value is now `deprecated` in favor of `max_completion_tokens`, and is not compatible with o1 series models.
   */
  maxTokens?: number | null | undefined;
  /**
   * An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens
   */
  maxCompletionTokens?: number | null | undefined;
  /**
   * Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.
   */
  logprobs?: boolean | null | undefined;
  /**
   * An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.
   */
  topLogprobs?: number | null | undefined;
  /**
   * How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs.
   */
  n?: number | null | undefined;
  /**
   * Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
   */
  presencePenalty?: number | null | undefined;
  /**
   * An object specifying the format that the model must output
   */
  responseFormat?:
    | CreatePromptResponseFormatText
    | CreatePromptResponseFormatJSONObject
    | CreatePromptResponseFormatJSONSchema
    | undefined;
  /**
   * Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
   *
   * @remarks
   *
   * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool calls are supported for all reasoning values in gpt-5.1.
   * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not support `none`.
   * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
   * - `xhigh` is currently only supported for `gpt-5.1-codex-max`.
   *
   * Any of "none", "minimal", "low", "medium", "high", "xhigh".
   */
  reasoningEffort?: CreatePromptReasoningEffort | undefined;
  /**
   * Adjusts response verbosity. Lower levels yield shorter answers.
   */
  verbosity?: string | undefined;
  /**
   * If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result.
   */
  seed?: number | null | undefined;
  /**
   * Up to 4 sequences where the API will stop generating further tokens.
   */
  stop?: string | Array<string> | null | undefined;
  /**
   * Options for streaming response. Only set this when you set stream: true.
   */
  streamOptions?: CreatePromptStreamOptions | null | undefined;
  thinking?:
    | components.ThinkingConfigDisabledSchema
    | components.ThinkingConfigEnabledSchema
    | undefined;
  /**
   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
   */
  temperature?: number | null | undefined;
  /**
   * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
   */
  topP?: number | null | undefined;
  /**
   * Limits the model to consider only the top k most likely tokens at each step.
   */
  topK?: number | null | undefined;
  /**
   * Controls which (if any) tool is called by the model.
   */
  toolChoice?: CreatePromptToolChoice2 | CreatePromptToolChoice1 | undefined;
  /**
   * Whether to enable parallel function calling during tool use.
   */
  parallelToolCalls?: boolean | undefined;
  /**
   * Output types that you would like the model to generate. Most models are capable of generating text, which is the default: ["text"]. The gpt-4o-audio-preview model can also be used to generate audio. To request that this model generate both text and audio responses, you can use: ["text", "audio"].
   */
  modalities?: Array<CreatePromptModalities> | null | undefined;
  /**
   * A list of guardrails to apply to the request.
   */
  guardrails?: Array<CreatePromptGuardrails> | undefined;
  /**
   * Array of fallback models to use if primary model fails
   */
  fallbacks?: Array<CreatePromptFallbacks> | undefined;
  /**
   * Retry configuration for the request
   */
  retry?: CreatePromptRetry | undefined;
  /**
   * Cache configuration for the request.
   */
  cache?: CreatePromptCache | undefined;
  /**
   * Array of models with weights for load balancing requests
   */
  loadBalancer?: Array<CreatePromptLoadBalancer1> | undefined;
  /**
   * Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured.
   */
  timeout?: CreatePromptTimeout | undefined;
};

export type CreatePromptRequestBody = {
  /**
   * The prompt’s name, meant to be displayable in the UI.
   */
  displayName: string;
  /**
   * The prompt’s description, meant to be displayable in the UI. Use this field to optionally store a long form explanation of the prompt for your own purpose
   */
  description?: string | null | undefined;
  metadata?: CreatePromptMetadata | undefined;
  /**
   * Prompt configuration with model and messages.
   */
  prompt?: PromptInput | undefined;
  /**
   * Entity storage path in the format: `project/folder/subfolder/...`
   *
   * @remarks
   *
   * The first element identifies the project, followed by nested folders (auto-created as needed).
   *
   * With project-based API keys, the first element is treated as a folder name, as the project is predetermined by the API key.
   */
  path: string;
};

export const CreatePromptPromptsType = {
  Prompt: "prompt",
} as const;
export type CreatePromptPromptsType = ClosedEnum<
  typeof CreatePromptPromptsType
>;

/**
 * The modality of the model
 */
export const ModelType = {
  Chat: "chat",
  Completion: "completion",
  Embedding: "embedding",
  Image: "image",
  Tts: "tts",
  Stt: "stt",
  Rerank: "rerank",
  Ocr: "ocr",
  Moderation: "moderation",
  Vision: "vision",
} as const;
/**
 * The modality of the model
 */
export type ModelType = ClosedEnum<typeof ModelType>;

/**
 * Only supported on `image` models.
 */
export const CreatePromptPromptsFormat = {
  Url: "url",
  B64Json: "b64_json",
  Text: "text",
  JsonObject: "json_object",
} as const;
/**
 * Only supported on `image` models.
 */
export type CreatePromptPromptsFormat = ClosedEnum<
  typeof CreatePromptPromptsFormat
>;

export const CreatePromptResponseFormat6 = {
  Json: "json",
  Text: "text",
  Srt: "srt",
  VerboseJson: "verbose_json",
  Vtt: "vtt",
} as const;
export type CreatePromptResponseFormat6 = ClosedEnum<
  typeof CreatePromptResponseFormat6
>;

export const CreatePromptResponseFormat5 = {
  Url: "url",
  Base64Json: "base64_json",
} as const;
export type CreatePromptResponseFormat5 = ClosedEnum<
  typeof CreatePromptResponseFormat5
>;

export const CreatePromptResponseFormat4 = {
  Mp3: "mp3",
  Opus: "opus",
  Aac: "aac",
  Flac: "flac",
  Wav: "wav",
  Pcm: "pcm",
} as const;
export type CreatePromptResponseFormat4 = ClosedEnum<
  typeof CreatePromptResponseFormat4
>;

export const CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigModelParametersType =
  {
    Text: "text",
  } as const;
export type CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigModelParametersType =
  ClosedEnum<
    typeof CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigModelParametersType
  >;

export type CreatePromptResponseFormat3 = {
  type:
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigModelParametersType;
};

export const CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigType =
  {
    JsonObject: "json_object",
  } as const;
export type CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigType =
  ClosedEnum<
    typeof CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigType
  >;

export type CreatePromptResponseFormat2 = {
  type:
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigType;
};

export const CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyType =
  {
    JsonSchema: "json_schema",
  } as const;
export type CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyType =
  ClosedEnum<
    typeof CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyType
  >;

export type CreatePromptResponseFormatPromptsResponse200ApplicationJSONJSONSchema =
  {
    name: string;
    description?: string | undefined;
    strict?: boolean | undefined;
    schema: { [k: string]: any };
  };

export type CreatePromptResponseFormat1 = {
  type:
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyType;
  displayName?: string | undefined;
  jsonSchema:
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONJSONSchema;
};

/**
 * An object specifying the format that the model must output.
 *
 * @remarks
 *
 *  Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema
 *
 *  Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.
 *
 * Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
 */
export type CreatePromptPromptsResponseResponseFormat =
  | CreatePromptResponseFormat1
  | CreatePromptResponseFormat2
  | CreatePromptResponseFormat3
  | CreatePromptResponseFormat4
  | CreatePromptResponseFormat5
  | CreatePromptResponseFormat6;

/**
 * The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider
 */
export const CreatePromptPhotoRealVersion = {
  V1: "v1",
  V2: "v2",
} as const;
/**
 * The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider
 */
export type CreatePromptPhotoRealVersion = ClosedEnum<
  typeof CreatePromptPhotoRealVersion
>;

/**
 * The format to return the embeddings
 */
export const CreatePromptEncodingFormat = {
  Float: "float",
  Base64: "base64",
} as const;
/**
 * The format to return the embeddings
 */
export type CreatePromptEncodingFormat = ClosedEnum<
  typeof CreatePromptEncodingFormat
>;

/**
 * Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
 */
export const CreatePromptPromptsResponseReasoningEffort = {
  None: "none",
  Disable: "disable",
  Minimal: "minimal",
  Low: "low",
  Medium: "medium",
  High: "high",
} as const;
/**
 * Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
 */
export type CreatePromptPromptsResponseReasoningEffort = ClosedEnum<
  typeof CreatePromptPromptsResponseReasoningEffort
>;

/**
 * Controls the verbosity of the model output.
 */
export const CreatePromptVerbosity = {
  Low: "low",
  Medium: "medium",
  High: "high",
} as const;
/**
 * Controls the verbosity of the model output.
 */
export type CreatePromptVerbosity = ClosedEnum<typeof CreatePromptVerbosity>;

/**
 * The level of thinking to use for the model. Only supported by `Google AI`
 */
export const CreatePromptThinkingLevel = {
  Low: "low",
  High: "high",
} as const;
/**
 * The level of thinking to use for the model. Only supported by `Google AI`
 */
export type CreatePromptThinkingLevel = ClosedEnum<
  typeof CreatePromptThinkingLevel
>;

/**
 * Model Parameters: Not all parameters apply to every model
 */
export type ModelParameters = {
  /**
   * Only supported on `chat` and `completion` models.
   */
  temperature?: number | undefined;
  /**
   * Only supported on `chat` and `completion` models.
   */
  maxTokens?: number | undefined;
  /**
   * Only supported on `chat` and `completion` models.
   */
  topK?: number | undefined;
  /**
   * Only supported on `chat` and `completion` models.
   */
  topP?: number | undefined;
  /**
   * Only supported on `chat` and `completion` models.
   */
  frequencyPenalty?: number | undefined;
  /**
   * Only supported on `chat` and `completion` models.
   */
  presencePenalty?: number | undefined;
  /**
   * Only supported on `image` models.
   */
  numImages?: number | undefined;
  /**
   * Best effort deterministic seed for the model. Currently only OpenAI models support these
   */
  seed?: number | undefined;
  /**
   * Only supported on `image` models.
   */
  format?: CreatePromptPromptsFormat | undefined;
  /**
   * Only supported on `image` models.
   */
  dimensions?: string | undefined;
  /**
   * Only supported on `image` models.
   */
  quality?: string | undefined;
  /**
   * Only supported on `image` models.
   */
  style?: string | undefined;
  /**
   * An object specifying the format that the model must output.
   *
   * @remarks
   *
   *  Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema
   *
   *  Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.
   *
   * Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
   */
  responseFormat?:
    | CreatePromptResponseFormat1
    | CreatePromptResponseFormat2
    | CreatePromptResponseFormat3
    | CreatePromptResponseFormat4
    | CreatePromptResponseFormat5
    | CreatePromptResponseFormat6
    | null
    | undefined;
  /**
   * The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider
   */
  photoRealVersion?: CreatePromptPhotoRealVersion | undefined;
  /**
   * The format to return the embeddings
   */
  encodingFormat?: CreatePromptEncodingFormat | undefined;
  /**
   * Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
   */
  reasoningEffort?: CreatePromptPromptsResponseReasoningEffort | undefined;
  /**
   * Gives the model enhanced reasoning capabilities for complex tasks. A value of 0 disables thinking. The minimum budget tokens for thinking are 1024. The Budget Tokens should never exceed the Max Tokens parameter. Only supported by `Anthropic`
   */
  budgetTokens?: number | undefined;
  /**
   * Controls the verbosity of the model output.
   */
  verbosity?: CreatePromptVerbosity | undefined;
  /**
   * The level of thinking to use for the model. Only supported by `Google AI`
   */
  thinkingLevel?: CreatePromptThinkingLevel | undefined;
};

export const CreatePromptProvider = {
  Openai: "openai",
  Groq: "groq",
  Cohere: "cohere",
  Azure: "azure",
  Aws: "aws",
  Google: "google",
  GoogleAi: "google-ai",
  Huggingface: "huggingface",
  Togetherai: "togetherai",
  Perplexity: "perplexity",
  Anthropic: "anthropic",
  Leonardoai: "leonardoai",
  Fal: "fal",
  Nvidia: "nvidia",
  Jina: "jina",
  Elevenlabs: "elevenlabs",
  Litellm: "litellm",
  Cerebras: "cerebras",
  Openailike: "openailike",
  Bytedance: "bytedance",
  Mistral: "mistral",
  Deepseek: "deepseek",
  Contextualai: "contextualai",
  Moonshotai: "moonshotai",
  Zai: "zai",
  Slack: "slack",
} as const;
export type CreatePromptProvider = ClosedEnum<typeof CreatePromptProvider>;

/**
 * The role of the prompt message
 */
export const CreatePromptRole = {
  System: "system",
  Assistant: "assistant",
  User: "user",
  Exception: "exception",
  Tool: "tool",
  Prompt: "prompt",
  Correction: "correction",
  ExpectedOutput: "expected_output",
} as const;
/**
 * The role of the prompt message
 */
export type CreatePromptRole = ClosedEnum<typeof CreatePromptRole>;

export type CreatePrompt2File = {
  /**
   * The file data as a data URI string in the format 'data:<mime-type>;base64,<base64-encoded-data>'. Example: 'data:image/png;base64,iVBORw0KGgoAAAANS...'
   */
  fileData?: string | undefined;
  /**
   * URL to the file. Only supported by Anthropic Claude models for PDF files.
   */
  uri?: string | undefined;
  /**
   * MIME type of the file (e.g., application/pdf, image/png)
   */
  mimeType?: string | undefined;
  /**
   * The name of the file, used when passing the file to the model as a string.
   */
  filename?: string | undefined;
};

export type CreatePrompt23 = {
  /**
   * The type of the content part. Always `file`.
   */
  type: "file";
  file: CreatePrompt2File;
};

export type CreatePrompt2ImageUrl = {
  /**
   * The orq.ai id of the image
   */
  id?: string | undefined;
  /**
   * Either a URL of the image or the base64 encoded data URI.
   */
  url: string;
  /**
   * Specifies the detail level of the image. Currently only supported with OpenAI models
   */
  detail?: string | undefined;
};

/**
 * The image part of the prompt message. Only supported with vision models.
 */
export type CreatePrompt22 = {
  type: "image_url";
  imageUrl: CreatePrompt2ImageUrl;
};

/**
 * Text content part of a prompt message
 */
export type CreatePrompt21 = {
  type: "text";
  text: string;
};

export type CreatePromptContentPromptsResponse2 =
  | CreatePrompt21
  | CreatePrompt22
  | CreatePrompt23;

/**
 * The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Can be null for tool messages in certain scenarios.
 */
export type CreatePromptContent =
  | string
  | Array<CreatePrompt21 | CreatePrompt22 | CreatePrompt23>;

export const CreatePromptPromptsResponse200Type = {
  Function: "function",
} as const;
export type CreatePromptPromptsResponse200Type = ClosedEnum<
  typeof CreatePromptPromptsResponse200Type
>;

export type CreatePromptFunction = {
  name: string;
  /**
   * JSON string arguments for the functions
   */
  arguments: string;
};

export type CreatePromptToolCalls = {
  id?: string | undefined;
  index?: number | undefined;
  type: CreatePromptPromptsResponse200Type;
  function: CreatePromptFunction;
};

export type CreatePromptPromptsMessages = {
  /**
   * The role of the prompt message
   */
  role: CreatePromptRole;
  /**
   * The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Can be null for tool messages in certain scenarios.
   */
  content:
    | string
    | Array<CreatePrompt21 | CreatePrompt22 | CreatePrompt23>
    | null;
  toolCalls?: Array<CreatePromptToolCalls> | undefined;
  toolCallId?: string | null | undefined;
};

/**
 * [DEPRECATED] Use the `prompt` property instead. A list of messages compatible with the openAI schema.
 *
 * @deprecated class: This will be removed in a future release, please migrate away from it as soon as possible.
 */
export type PromptConfig = {
  stream?: boolean | undefined;
  model?: string | null | undefined;
  /**
   * The id of the resource
   */
  modelDbId?: string | null | undefined;
  /**
   * The modality of the model
   */
  modelType?: ModelType | null | undefined;
  /**
   * Model Parameters: Not all parameters apply to every model
   */
  modelParameters?: ModelParameters | undefined;
  provider?: CreatePromptProvider | null | undefined;
  /**
   * The ID of the integration to use
   */
  integrationId?: string | null | undefined;
  version?: string | undefined;
  messages: Array<CreatePromptPromptsMessages>;
};

/**
 * The voice the model uses to respond. Supported voices are alloy, echo, fable, onyx, nova, and shimmer.
 */
export const CreatePromptPromptsVoice = {
  Alloy: "alloy",
  Echo: "echo",
  Fable: "fable",
  Onyx: "onyx",
  Nova: "nova",
  Shimmer: "shimmer",
} as const;
/**
 * The voice the model uses to respond. Supported voices are alloy, echo, fable, onyx, nova, and shimmer.
 */
export type CreatePromptPromptsVoice = ClosedEnum<
  typeof CreatePromptPromptsVoice
>;

/**
 * Specifies the output audio format. Must be one of wav, mp3, flac, opus, or pcm16.
 */
export const CreatePromptPromptsResponse200Format = {
  Wav: "wav",
  Mp3: "mp3",
  Flac: "flac",
  Opus: "opus",
  Pcm16: "pcm16",
} as const;
/**
 * Specifies the output audio format. Must be one of wav, mp3, flac, opus, or pcm16.
 */
export type CreatePromptPromptsResponse200Format = ClosedEnum<
  typeof CreatePromptPromptsResponse200Format
>;

/**
 * Parameters for audio output. Required when audio output is requested with modalities: ["audio"]. Learn more.
 */
export type CreatePromptPromptsAudio = {
  /**
   * The voice the model uses to respond. Supported voices are alloy, echo, fable, onyx, nova, and shimmer.
   */
  voice: CreatePromptPromptsVoice;
  /**
   * Specifies the output audio format. Must be one of wav, mp3, flac, opus, or pcm16.
   */
  format: CreatePromptPromptsResponse200Format;
};

export type CreatePromptResponseFormatPromptsResponseJsonSchema = {
  /**
   * A description of what the response format is for, used by the model to determine how to respond in the format.
   */
  description?: string | undefined;
  /**
   * The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
   */
  name: string;
  /**
   * The schema for the response format, described as a JSON Schema object.
   */
  schema?: any | undefined;
  /**
   * Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true.
   */
  strict: boolean;
};

/**
 * @remarks
 *
 * JSON Schema response format. Used to generate structured JSON responses
 */
export type CreatePromptResponseFormatPromptsResponse200JSONSchema = {
  type: "json_schema";
  jsonSchema: CreatePromptResponseFormatPromptsResponseJsonSchema;
};

/**
 * @remarks
 *
 * JSON object response format. An older method of generating JSON responses. Using `json_schema` is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.
 */
export type CreatePromptResponseFormatPromptsJSONObject = {
  type: "json_object";
};

/**
 * @remarks
 *
 * Default response format. Used to generate text responses
 */
export type CreatePromptResponseFormatPromptsText = {
  type: "text";
};

/**
 * An object specifying the format that the model must output
 */
export type CreatePromptPromptsResponseFormat =
  | CreatePromptResponseFormatPromptsText
  | CreatePromptResponseFormatPromptsJSONObject
  | CreatePromptResponseFormatPromptsResponse200JSONSchema;

/**
 * Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
 *
 * @remarks
 *
 * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool calls are supported for all reasoning values in gpt-5.1.
 * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not support `none`.
 * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
 * - `xhigh` is currently only supported for `gpt-5.1-codex-max`.
 *
 * Any of "none", "minimal", "low", "medium", "high", "xhigh".
 */
export const CreatePromptPromptsReasoningEffort = {
  None: "none",
  Minimal: "minimal",
  Low: "low",
  Medium: "medium",
  High: "high",
  Xhigh: "xhigh",
} as const;
/**
 * Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
 *
 * @remarks
 *
 * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool calls are supported for all reasoning values in gpt-5.1.
 * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not support `none`.
 * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
 * - `xhigh` is currently only supported for `gpt-5.1-codex-max`.
 *
 * Any of "none", "minimal", "low", "medium", "high", "xhigh".
 */
export type CreatePromptPromptsReasoningEffort = ClosedEnum<
  typeof CreatePromptPromptsReasoningEffort
>;

/**
 * Up to 4 sequences where the API will stop generating further tokens.
 */
export type CreatePromptPromptsStop = string | Array<string>;

/**
 * Options for streaming response. Only set this when you set stream: true.
 */
export type CreatePromptPromptsStreamOptions = {
  /**
   * If set, an additional chunk will be streamed before the data: [DONE] message. The usage field on this chunk shows the token usage statistics for the entire request, and the choices field will always be an empty array. All other chunks will also include a usage field, but with a null value.
   */
  includeUsage?: boolean | undefined;
};

export type CreatePromptPromptsThinking =
  | components.ThinkingConfigDisabledSchema
  | components.ThinkingConfigEnabledSchema;

/**
 * The type of the tool. Currently, only function is supported.
 */
export const CreatePromptToolChoicePromptsType = {
  Function: "function",
} as const;
/**
 * The type of the tool. Currently, only function is supported.
 */
export type CreatePromptToolChoicePromptsType = ClosedEnum<
  typeof CreatePromptToolChoicePromptsType
>;

export type CreatePromptToolChoicePromptsFunction = {
  /**
   * The name of the function to call.
   */
  name: string;
};

export type CreatePromptToolChoicePrompts2 = {
  /**
   * The type of the tool. Currently, only function is supported.
   */
  type?: CreatePromptToolChoicePromptsType | undefined;
  function: CreatePromptToolChoicePromptsFunction;
};

export const CreatePromptToolChoicePrompts1 = {
  None: "none",
  Auto: "auto",
  Required: "required",
} as const;
export type CreatePromptToolChoicePrompts1 = ClosedEnum<
  typeof CreatePromptToolChoicePrompts1
>;

/**
 * Controls which (if any) tool is called by the model.
 */
export type CreatePromptPromptsToolChoice =
  | CreatePromptToolChoicePrompts2
  | CreatePromptToolChoicePrompts1;

export const CreatePromptPromptsModalities = {
  Text: "text",
  Audio: "audio",
} as const;
export type CreatePromptPromptsModalities = ClosedEnum<
  typeof CreatePromptPromptsModalities
>;

/**
 * The key of the guardrail.
 */
export const CreatePromptIdPrompts1 = {
  OrqPiiDetection: "orq_pii_detection",
  OrqSexualModeration: "orq_sexual_moderation",
  OrqHarmfulModeration: "orq_harmful_moderation",
} as const;
/**
 * The key of the guardrail.
 */
export type CreatePromptIdPrompts1 = ClosedEnum<typeof CreatePromptIdPrompts1>;

export type CreatePromptPromptsId = CreatePromptIdPrompts1 | string;

/**
 * Determines whether the guardrail runs on the input (user message) or output (model response).
 */
export const CreatePromptPromptsExecuteOn = {
  Input: "input",
  Output: "output",
} as const;
/**
 * Determines whether the guardrail runs on the input (user message) or output (model response).
 */
export type CreatePromptPromptsExecuteOn = ClosedEnum<
  typeof CreatePromptPromptsExecuteOn
>;

export type CreatePromptPromptsGuardrails = {
  id: CreatePromptIdPrompts1 | string;
  /**
   * Determines whether the guardrail runs on the input (user message) or output (model response).
   */
  executeOn: CreatePromptPromptsExecuteOn;
};

export type CreatePromptPromptsFallbacks = {
  /**
   * Fallback model identifier
   */
  model: string;
};

/**
 * Retry configuration for the request
 */
export type CreatePromptPromptsRetry = {
  /**
   * Number of retry attempts (1-5)
   */
  count: number;
  /**
   * HTTP status codes that trigger retry logic
   */
  onCodes?: Array<number> | undefined;
};

export const CreatePromptPromptsResponseType = {
  ExactMatch: "exact_match",
} as const;
export type CreatePromptPromptsResponseType = ClosedEnum<
  typeof CreatePromptPromptsResponseType
>;

/**
 * Cache configuration for the request.
 */
export type CreatePromptPromptsCache = {
  /**
   * Time to live for cached responses in seconds. Maximum 259200 seconds (3 days).
   */
  ttl: number;
  type: CreatePromptPromptsResponseType;
};

export const CreatePromptLoadBalancerPromptsType = {
  WeightBased: "weight_based",
} as const;
export type CreatePromptLoadBalancerPromptsType = ClosedEnum<
  typeof CreatePromptLoadBalancerPromptsType
>;

export type CreatePromptLoadBalancerPrompts1 = {
  type: CreatePromptLoadBalancerPromptsType;
  /**
   * Model identifier for load balancing
   */
  model: string;
  /**
   * Weight assigned to this model for load balancing
   */
  weight: number;
};

export type CreatePromptPromptsLoadBalancer = CreatePromptLoadBalancerPrompts1;

/**
 * Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured.
 */
export type CreatePromptPromptsTimeout = {
  /**
   * Timeout value in milliseconds
   */
  callTimeout: number;
};

export type CreatePromptContentPromptsResponse200ApplicationJSONResponseBody2 =
  components.TextContentPartSchema;

/**
 * The contents of the tool message.
 */
export type CreatePromptMessagesPromptsResponse200ApplicationJSONResponseBodyContent =
  | string
  | Array<components.TextContentPartSchema>;

/**
 * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
 */
export const CreatePromptMessagesPromptsResponse200Type = {
  Ephemeral: "ephemeral",
} as const;
/**
 * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
 */
export type CreatePromptMessagesPromptsResponse200Type = ClosedEnum<
  typeof CreatePromptMessagesPromptsResponse200Type
>;

/**
 * The time-to-live for the cache control breakpoint. This may be one of the following values:
 *
 * @remarks
 *
 * - `5m`: 5 minutes
 * - `1h`: 1 hour
 *
 * Defaults to `5m`. Only supported by `Anthropic` Claude models.
 */
export const CreatePromptMessagesPromptsTtl = {
  Fivem: "5m",
  Oneh: "1h",
} as const;
/**
 * The time-to-live for the cache control breakpoint. This may be one of the following values:
 *
 * @remarks
 *
 * - `5m`: 5 minutes
 * - `1h`: 1 hour
 *
 * Defaults to `5m`. Only supported by `Anthropic` Claude models.
 */
export type CreatePromptMessagesPromptsTtl = ClosedEnum<
  typeof CreatePromptMessagesPromptsTtl
>;

export type CreatePromptMessagesPromptsCacheControl = {
  /**
   * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
   */
  type: CreatePromptMessagesPromptsResponse200Type;
  /**
   * The time-to-live for the cache control breakpoint. This may be one of the following values:
   *
   * @remarks
   *
   * - `5m`: 5 minutes
   * - `1h`: 1 hour
   *
   * Defaults to `5m`. Only supported by `Anthropic` Claude models.
   */
  ttl: CreatePromptMessagesPromptsTtl;
};

export type CreatePromptMessagesPromptsToolMessage = {
  /**
   * The role of the messages author, in this case tool.
   */
  role: "tool";
  /**
   * The contents of the tool message.
   */
  content: string | Array<components.TextContentPartSchema>;
  /**
   * Tool call that this message is responding to.
   */
  toolCallId: string | null;
  cacheControl?: CreatePromptMessagesPromptsCacheControl | undefined;
};

export type CreatePromptContentPromptsResponse200ApplicationJson2 =
  | (components.TextContentPartSchema & { type: "text" })
  | components.RefusalPartSchema
  | components.ReasoningPartSchema
  | components.RedactedReasoningPartSchema;

/**
 * The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
 */
export type CreatePromptMessagesPromptsResponse200ApplicationJSONContent =
  | string
  | Array<
    | (components.TextContentPartSchema & { type: "text" })
    | components.RefusalPartSchema
    | components.ReasoningPartSchema
    | components.RedactedReasoningPartSchema
  >;

/**
 * Data about a previous audio response from the model.
 */
export type CreatePromptMessagesPromptsAudio = {
  /**
   * Unique identifier for a previous audio response from the model.
   */
  id: string;
};

/**
 * The type of the tool. Currently, only `function` is supported.
 */
export const CreatePromptMessagesPromptsResponseType = {
  Function: "function",
} as const;
/**
 * The type of the tool. Currently, only `function` is supported.
 */
export type CreatePromptMessagesPromptsResponseType = ClosedEnum<
  typeof CreatePromptMessagesPromptsResponseType
>;

export type CreatePromptMessagesPromptsFunction = {
  /**
   * The name of the function to call.
   */
  name?: string | undefined;
  /**
   * The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
   */
  arguments?: string | undefined;
};

export type CreatePromptMessagesPromptsToolCalls = {
  /**
   * The ID of the tool call.
   */
  id: string;
  /**
   * The type of the tool. Currently, only `function` is supported.
   */
  type: CreatePromptMessagesPromptsResponseType;
  function: CreatePromptMessagesPromptsFunction;
  /**
   * Encrypted representation of the model internal reasoning state during function calling. Required by Gemini 3 models when continuing a conversation after a tool call.
   */
  thoughtSignature?: string | undefined;
};

export type CreatePromptMessagesPromptsAssistantMessage = {
  /**
   * The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
   */
  content?:
    | string
    | Array<
      | (components.TextContentPartSchema & { type: "text" })
      | components.RefusalPartSchema
      | components.ReasoningPartSchema
      | components.RedactedReasoningPartSchema
    >
    | null
    | undefined;
  /**
   * The refusal message by the assistant.
   */
  refusal?: string | null | undefined;
  /**
   * The role of the messages author, in this case `assistant`.
   */
  role: "assistant";
  /**
   * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
   */
  name?: string | undefined;
  /**
   * Data about a previous audio response from the model.
   */
  audio?: CreatePromptMessagesPromptsAudio | null | undefined;
  /**
   * The tool calls generated by the model, such as function calls.
   */
  toolCalls?: Array<CreatePromptMessagesPromptsToolCalls> | undefined;
};

/**
 * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
 */
export const CreatePrompt2PromptsResponse200ApplicationJSONResponseBodyPromptType =
  {
    Ephemeral: "ephemeral",
  } as const;
/**
 * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
 */
export type CreatePrompt2PromptsResponse200ApplicationJSONResponseBodyPromptType =
  ClosedEnum<
    typeof CreatePrompt2PromptsResponse200ApplicationJSONResponseBodyPromptType
  >;

/**
 * The time-to-live for the cache control breakpoint. This may be one of the following values:
 *
 * @remarks
 *
 * - `5m`: 5 minutes
 * - `1h`: 1 hour
 *
 * Defaults to `5m`. Only supported by `Anthropic` Claude models.
 */
export const CreatePrompt2PromptsTtl = {
  Fivem: "5m",
  Oneh: "1h",
} as const;
/**
 * The time-to-live for the cache control breakpoint. This may be one of the following values:
 *
 * @remarks
 *
 * - `5m`: 5 minutes
 * - `1h`: 1 hour
 *
 * Defaults to `5m`. Only supported by `Anthropic` Claude models.
 */
export type CreatePrompt2PromptsTtl = ClosedEnum<
  typeof CreatePrompt2PromptsTtl
>;

export type CreatePrompt2PromptsCacheControl = {
  /**
   * Create a cache control breakpoint at this content block. Accepts only the value "ephemeral".
   */
  type: CreatePrompt2PromptsResponse200ApplicationJSONResponseBodyPromptType;
  /**
   * The time-to-live for the cache control breakpoint. This may be one of the following values:
   *
   * @remarks
   *
   * - `5m`: 5 minutes
   * - `1h`: 1 hour
   *
   * Defaults to `5m`. Only supported by `Anthropic` Claude models.
   */
  ttl: CreatePrompt2PromptsTtl;
};

export type CreatePrompt2Prompts4 = {
  /**
   * The type of the content part. Always `file`.
   */
  type: "file";
  cacheControl?: CreatePrompt2PromptsCacheControl | undefined;
  /**
   * File data for the content part. Must contain either file_data or uri, but not both.
   */
  file: components.FileContentPartSchema;
};

export type CreatePromptContentPromptsResponse2002 =
  | (components.TextContentPartSchema & { type: "text" })
  | components.ImageContentPartSchema
  | components.AudioContentPartSchema
  | CreatePrompt2Prompts4;

/**
 * The contents of the user message.
 */
export type CreatePromptMessagesPromptsResponse200Content =
  | string
  | Array<
    | (components.TextContentPartSchema & { type: "text" })
    | components.ImageContentPartSchema
    | components.AudioContentPartSchema
    | CreatePrompt2Prompts4
  >;

export type CreatePromptMessagesPromptsUserMessage = {
  /**
   * The role of the messages author, in this case `user`.
   */
  role: "user";
  /**
   * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
   */
  name?: string | undefined;
  /**
   * The contents of the user message.
   */
  content:
    | string
    | Array<
      | (components.TextContentPartSchema & { type: "text" })
      | components.ImageContentPartSchema
      | components.AudioContentPartSchema
      | CreatePrompt2Prompts4
    >;
};

/**
 * The contents of the system message.
 */
export type CreatePromptMessagesPromptsResponseContent =
  | string
  | Array<components.TextContentPartSchema>;

/**
 * Developer-provided instructions that the model should follow, regardless of messages sent by the user.
 */
export type CreatePromptMessagesPromptsSystemMessage = {
  /**
   * The role of the messages author, in this case `system`.
   */
  role: "system";
  /**
   * The contents of the system message.
   */
  content: string | Array<components.TextContentPartSchema>;
  /**
   * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
   */
  name?: string | undefined;
};

export type CreatePromptPromptsResponseMessages =
  | CreatePromptMessagesPromptsSystemMessage
  | CreatePromptMessagesPromptsUserMessage
  | CreatePromptMessagesPromptsAssistantMessage
  | CreatePromptMessagesPromptsToolMessage;

/**
 * Prompt configuration with model and messages. Use this instead of prompt_config.
 */
export type PromptField = {
  /**
   * Parameters for audio output. Required when audio output is requested with modalities: ["audio"]. Learn more.
   */
  audio?: CreatePromptPromptsAudio | null | undefined;
  /**
   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
   */
  frequencyPenalty?: number | null | undefined;
  /**
   * `[Deprecated]`. The maximum number of tokens that can be generated in the chat completion. This value can be used to control costs for text generated via API.
   *
   * @remarks
   *
   *  This value is now `deprecated` in favor of `max_completion_tokens`, and is not compatible with o1 series models.
   */
  maxTokens?: number | null | undefined;
  /**
   * An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens
   */
  maxCompletionTokens?: number | null | undefined;
  /**
   * Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.
   */
  logprobs?: boolean | null | undefined;
  /**
   * An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.
   */
  topLogprobs?: number | null | undefined;
  /**
   * How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs.
   */
  n?: number | null | undefined;
  /**
   * Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
   */
  presencePenalty?: number | null | undefined;
  /**
   * An object specifying the format that the model must output
   */
  responseFormat?:
    | CreatePromptResponseFormatPromptsText
    | CreatePromptResponseFormatPromptsJSONObject
    | CreatePromptResponseFormatPromptsResponse200JSONSchema
    | undefined;
  /**
   * Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
   *
   * @remarks
   *
   * - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool calls are supported for all reasoning values in gpt-5.1.
   * - All models before `gpt-5.1` default to `medium` reasoning effort, and do not support `none`.
   * - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
   * - `xhigh` is currently only supported for `gpt-5.1-codex-max`.
   *
   * Any of "none", "minimal", "low", "medium", "high", "xhigh".
   */
  reasoningEffort?: CreatePromptPromptsReasoningEffort | undefined;
  /**
   * Adjusts response verbosity. Lower levels yield shorter answers.
   */
  verbosity?: string | undefined;
  /**
   * If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result.
   */
  seed?: number | null | undefined;
  /**
   * Up to 4 sequences where the API will stop generating further tokens.
   */
  stop?: string | Array<string> | null | undefined;
  /**
   * Options for streaming response. Only set this when you set stream: true.
   */
  streamOptions?: CreatePromptPromptsStreamOptions | null | undefined;
  thinking?:
    | components.ThinkingConfigDisabledSchema
    | components.ThinkingConfigEnabledSchema
    | undefined;
  /**
   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
   */
  temperature?: number | null | undefined;
  /**
   * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
   */
  topP?: number | null | undefined;
  /**
   * Limits the model to consider only the top k most likely tokens at each step.
   */
  topK?: number | null | undefined;
  /**
   * Controls which (if any) tool is called by the model.
   */
  toolChoice?:
    | CreatePromptToolChoicePrompts2
    | CreatePromptToolChoicePrompts1
    | undefined;
  /**
   * Whether to enable parallel function calling during tool use.
   */
  parallelToolCalls?: boolean | undefined;
  /**
   * Output types that you would like the model to generate. Most models are capable of generating text, which is the default: ["text"]. The gpt-4o-audio-preview model can also be used to generate audio. To request that this model generate both text and audio responses, you can use: ["text", "audio"].
   */
  modalities?: Array<CreatePromptPromptsModalities> | null | undefined;
  /**
   * A list of guardrails to apply to the request.
   */
  guardrails?: Array<CreatePromptPromptsGuardrails> | undefined;
  /**
   * Array of fallback models to use if primary model fails
   */
  fallbacks?: Array<CreatePromptPromptsFallbacks> | undefined;
  /**
   * Retry configuration for the request
   */
  retry?: CreatePromptPromptsRetry | undefined;
  /**
   * Cache configuration for the request.
   */
  cache?: CreatePromptPromptsCache | undefined;
  /**
   * Array of models with weights for load balancing requests
   */
  loadBalancer?: Array<CreatePromptLoadBalancerPrompts1> | undefined;
  /**
   * Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured.
   */
  timeout?: CreatePromptPromptsTimeout | undefined;
  /**
   * Array of messages that make up the conversation. Each message has a role (system, user, assistant, or tool) and content.
   */
  messages?:
    | Array<
      | CreatePromptMessagesPromptsSystemMessage
      | CreatePromptMessagesPromptsUserMessage
      | CreatePromptMessagesPromptsAssistantMessage
      | CreatePromptMessagesPromptsToolMessage
    >
    | undefined;
  /**
   * Model ID used to generate the response, like `openai/gpt-4o` or `anthropic/claude-3-5-sonnet-20241022`. For private models, use format: `{workspaceKey}@{provider}/{model}`.
   */
  model?: string | null | undefined;
  version?: string | undefined;
};

export const CreatePromptUseCases = {
  AgentsSimulations: "Agents simulations",
  Agents: "Agents",
  APIInteraction: "API interaction",
  AutonomousAgents: "Autonomous Agents",
  Chatbots: "Chatbots",
  Classification: "Classification",
  CodeUnderstanding: "Code understanding",
  CodeWriting: "Code writing",
  Conversation: "Conversation",
  DocumentsQA: "Documents QA",
  Evaluation: "Evaluation",
  Extraction: "Extraction",
  MultiModal: "Multi-modal",
  SelfChecking: "Self-checking",
  SentimentAnalysis: "Sentiment analysis",
  Sql: "SQL",
  Summarization: "Summarization",
  Tagging: "Tagging",
  TranslationDocument: "Translation (document)",
  TranslationSentences: "Translation (sentences)",
} as const;
export type CreatePromptUseCases = ClosedEnum<typeof CreatePromptUseCases>;

/**
 * The language that the prompt is written in. Use this field to categorize the prompt for your own purpose
 */
export const CreatePromptPromptsLanguage = {
  Chinese: "Chinese",
  Dutch: "Dutch",
  English: "English",
  French: "French",
  German: "German",
  Russian: "Russian",
  Spanish: "Spanish",
} as const;
/**
 * The language that the prompt is written in. Use this field to categorize the prompt for your own purpose
 */
export type CreatePromptPromptsLanguage = ClosedEnum<
  typeof CreatePromptPromptsLanguage
>;

export type CreatePromptPromptsMetadata = {
  /**
   * A list of use cases that the prompt is meant to be used for. Use this field to categorize the prompt for your own purpose
   */
  useCases?: Array<CreatePromptUseCases> | undefined;
  /**
   * The language that the prompt is written in. Use this field to categorize the prompt for your own purpose
   */
  language?: CreatePromptPromptsLanguage | null | undefined;
};

/**
 * A prompt entity with configuration, metadata, and versioning.
 */
export type CreatePromptPrompt = {
  id: string;
  type: CreatePromptPromptsType;
  owner: string;
  domainId: string;
  created: string;
  updated: string;
  createdById?: string | null | undefined;
  updatedById?: string | null | undefined;
  /**
   * The prompt’s name, meant to be displayable in the UI.
   */
  displayName: string;
  /**
   * The prompt’s description, meant to be displayable in the UI. Use this field to optionally store a long form explanation of the prompt for your own purpose
   */
  description?: string | null | undefined;
  /**
   * [DEPRECATED] Use the `prompt` property instead. A list of messages compatible with the openAI schema.
   *
   * @deprecated field: This will be removed in a future release, please migrate away from it as soon as possible.
   */
  promptConfig?: PromptConfig | undefined;
  /**
   * Prompt configuration with model and messages. Use this instead of prompt_config.
   */
  prompt: PromptField;
  metadata?: CreatePromptPromptsMetadata | undefined;
};

/** @internal */
export const UseCases$outboundSchema: z.ZodNativeEnum<typeof UseCases> = z
  .nativeEnum(UseCases);

/** @internal */
export const CreatePromptLanguage$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptLanguage
> = z.nativeEnum(CreatePromptLanguage);

/** @internal */
export type CreatePromptMetadata$Outbound = {
  use_cases?: Array<string> | undefined;
  language?: string | null | undefined;
};

/** @internal */
export const CreatePromptMetadata$outboundSchema: z.ZodType<
  CreatePromptMetadata$Outbound,
  z.ZodTypeDef,
  CreatePromptMetadata
> = z.object({
  useCases: z.array(UseCases$outboundSchema).optional(),
  language: z.nullable(CreatePromptLanguage$outboundSchema).optional(),
}).transform((v) => {
  return remap$(v, {
    useCases: "use_cases",
  });
});

export function createPromptMetadataToJSON(
  createPromptMetadata: CreatePromptMetadata,
): string {
  return JSON.stringify(
    CreatePromptMetadata$outboundSchema.parse(createPromptMetadata),
  );
}

/** @internal */
export type CreatePromptContentPromptsRequest2$Outbound =
  components.TextContentPartSchema$Outbound;

/** @internal */
export const CreatePromptContentPromptsRequest2$outboundSchema: z.ZodType<
  CreatePromptContentPromptsRequest2$Outbound,
  z.ZodTypeDef,
  CreatePromptContentPromptsRequest2
> = components.TextContentPartSchema$outboundSchema;

export function createPromptContentPromptsRequest2ToJSON(
  createPromptContentPromptsRequest2: CreatePromptContentPromptsRequest2,
): string {
  return JSON.stringify(
    CreatePromptContentPromptsRequest2$outboundSchema.parse(
      createPromptContentPromptsRequest2,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesPromptsRequestRequestBodyContent$Outbound =
  | string
  | Array<components.TextContentPartSchema$Outbound>;

/** @internal */
export const CreatePromptMessagesPromptsRequestRequestBodyContent$outboundSchema:
  z.ZodType<
    CreatePromptMessagesPromptsRequestRequestBodyContent$Outbound,
    z.ZodTypeDef,
    CreatePromptMessagesPromptsRequestRequestBodyContent
  > = z.union([
    z.string(),
    z.array(components.TextContentPartSchema$outboundSchema),
  ]);

export function createPromptMessagesPromptsRequestRequestBodyContentToJSON(
  createPromptMessagesPromptsRequestRequestBodyContent:
    CreatePromptMessagesPromptsRequestRequestBodyContent,
): string {
  return JSON.stringify(
    CreatePromptMessagesPromptsRequestRequestBodyContent$outboundSchema.parse(
      createPromptMessagesPromptsRequestRequestBodyContent,
    ),
  );
}

/** @internal */
export const CreatePromptMessagesPromptsType$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptMessagesPromptsType
> = z.nativeEnum(CreatePromptMessagesPromptsType);

/** @internal */
export const CreatePromptMessagesTtl$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptMessagesTtl
> = z.nativeEnum(CreatePromptMessagesTtl);

/** @internal */
export type CreatePromptMessagesCacheControl$Outbound = {
  type: string;
  ttl: string;
};

/** @internal */
export const CreatePromptMessagesCacheControl$outboundSchema: z.ZodType<
  CreatePromptMessagesCacheControl$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesCacheControl
> = z.object({
  type: CreatePromptMessagesPromptsType$outboundSchema,
  ttl: CreatePromptMessagesTtl$outboundSchema.default("5m"),
});

export function createPromptMessagesCacheControlToJSON(
  createPromptMessagesCacheControl: CreatePromptMessagesCacheControl,
): string {
  return JSON.stringify(
    CreatePromptMessagesCacheControl$outboundSchema.parse(
      createPromptMessagesCacheControl,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesToolMessage$Outbound = {
  role: "tool";
  content: string | Array<components.TextContentPartSchema$Outbound>;
  tool_call_id: string | null;
  cache_control?: CreatePromptMessagesCacheControl$Outbound | undefined;
};

/** @internal */
export const CreatePromptMessagesToolMessage$outboundSchema: z.ZodType<
  CreatePromptMessagesToolMessage$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesToolMessage
> = z.object({
  role: z.literal("tool"),
  content: z.union([
    z.string(),
    z.array(components.TextContentPartSchema$outboundSchema),
  ]),
  toolCallId: z.nullable(z.string()),
  cacheControl: z.lazy(() => CreatePromptMessagesCacheControl$outboundSchema)
    .optional(),
}).transform((v) => {
  return remap$(v, {
    toolCallId: "tool_call_id",
    cacheControl: "cache_control",
  });
});

export function createPromptMessagesToolMessageToJSON(
  createPromptMessagesToolMessage: CreatePromptMessagesToolMessage,
): string {
  return JSON.stringify(
    CreatePromptMessagesToolMessage$outboundSchema.parse(
      createPromptMessagesToolMessage,
    ),
  );
}

/** @internal */
export type CreatePromptContentPrompts2$Outbound =
  | (components.TextContentPartSchema$Outbound & { type: "text" })
  | components.RefusalPartSchema$Outbound
  | components.ReasoningPartSchema$Outbound
  | components.RedactedReasoningPartSchema$Outbound;

/** @internal */
export const CreatePromptContentPrompts2$outboundSchema: z.ZodType<
  CreatePromptContentPrompts2$Outbound,
  z.ZodTypeDef,
  CreatePromptContentPrompts2
> = z.union([
  components.TextContentPartSchema$outboundSchema.and(
    z.object({ type: z.literal("text") }),
  ),
  components.RefusalPartSchema$outboundSchema,
  components.ReasoningPartSchema$outboundSchema,
  components.RedactedReasoningPartSchema$outboundSchema,
]);

export function createPromptContentPrompts2ToJSON(
  createPromptContentPrompts2: CreatePromptContentPrompts2,
): string {
  return JSON.stringify(
    CreatePromptContentPrompts2$outboundSchema.parse(
      createPromptContentPrompts2,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesPromptsRequestContent$Outbound =
  | string
  | Array<
    | (components.TextContentPartSchema$Outbound & { type: "text" })
    | components.RefusalPartSchema$Outbound
    | components.ReasoningPartSchema$Outbound
    | components.RedactedReasoningPartSchema$Outbound
  >;

/** @internal */
export const CreatePromptMessagesPromptsRequestContent$outboundSchema:
  z.ZodType<
    CreatePromptMessagesPromptsRequestContent$Outbound,
    z.ZodTypeDef,
    CreatePromptMessagesPromptsRequestContent
  > = z.union([
    z.string(),
    z.array(
      z.union([
        components.TextContentPartSchema$outboundSchema.and(
          z.object({ type: z.literal("text") }),
        ),
        components.RefusalPartSchema$outboundSchema,
        components.ReasoningPartSchema$outboundSchema,
        components.RedactedReasoningPartSchema$outboundSchema,
      ]),
    ),
  ]);

export function createPromptMessagesPromptsRequestContentToJSON(
  createPromptMessagesPromptsRequestContent:
    CreatePromptMessagesPromptsRequestContent,
): string {
  return JSON.stringify(
    CreatePromptMessagesPromptsRequestContent$outboundSchema.parse(
      createPromptMessagesPromptsRequestContent,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesAudio$Outbound = {
  id: string;
};

/** @internal */
export const CreatePromptMessagesAudio$outboundSchema: z.ZodType<
  CreatePromptMessagesAudio$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesAudio
> = z.object({
  id: z.string(),
});

export function createPromptMessagesAudioToJSON(
  createPromptMessagesAudio: CreatePromptMessagesAudio,
): string {
  return JSON.stringify(
    CreatePromptMessagesAudio$outboundSchema.parse(createPromptMessagesAudio),
  );
}

/** @internal */
export const CreatePromptMessagesType$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptMessagesType
> = z.nativeEnum(CreatePromptMessagesType);

/** @internal */
export type CreatePromptMessagesFunction$Outbound = {
  name?: string | undefined;
  arguments?: string | undefined;
};

/** @internal */
export const CreatePromptMessagesFunction$outboundSchema: z.ZodType<
  CreatePromptMessagesFunction$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesFunction
> = z.object({
  name: z.string().optional(),
  arguments: z.string().optional(),
});

export function createPromptMessagesFunctionToJSON(
  createPromptMessagesFunction: CreatePromptMessagesFunction,
): string {
  return JSON.stringify(
    CreatePromptMessagesFunction$outboundSchema.parse(
      createPromptMessagesFunction,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesToolCalls$Outbound = {
  id: string;
  type: string;
  function: CreatePromptMessagesFunction$Outbound;
  thought_signature?: string | undefined;
};

/** @internal */
export const CreatePromptMessagesToolCalls$outboundSchema: z.ZodType<
  CreatePromptMessagesToolCalls$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesToolCalls
> = z.object({
  id: z.string(),
  type: CreatePromptMessagesType$outboundSchema,
  function: z.lazy(() => CreatePromptMessagesFunction$outboundSchema),
  thoughtSignature: z.string().optional(),
}).transform((v) => {
  return remap$(v, {
    thoughtSignature: "thought_signature",
  });
});

export function createPromptMessagesToolCallsToJSON(
  createPromptMessagesToolCalls: CreatePromptMessagesToolCalls,
): string {
  return JSON.stringify(
    CreatePromptMessagesToolCalls$outboundSchema.parse(
      createPromptMessagesToolCalls,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesAssistantMessage$Outbound = {
  content?:
    | string
    | Array<
      | (components.TextContentPartSchema$Outbound & { type: "text" })
      | components.RefusalPartSchema$Outbound
      | components.ReasoningPartSchema$Outbound
      | components.RedactedReasoningPartSchema$Outbound
    >
    | null
    | undefined;
  refusal?: string | null | undefined;
  role: "assistant";
  name?: string | undefined;
  audio?: CreatePromptMessagesAudio$Outbound | null | undefined;
  tool_calls?: Array<CreatePromptMessagesToolCalls$Outbound> | undefined;
};

/** @internal */
export const CreatePromptMessagesAssistantMessage$outboundSchema: z.ZodType<
  CreatePromptMessagesAssistantMessage$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesAssistantMessage
> = z.object({
  content: z.nullable(
    z.union([
      z.string(),
      z.array(
        z.union([
          components.TextContentPartSchema$outboundSchema.and(
            z.object({ type: z.literal("text") }),
          ),
          components.RefusalPartSchema$outboundSchema,
          components.ReasoningPartSchema$outboundSchema,
          components.RedactedReasoningPartSchema$outboundSchema,
        ]),
      ),
    ]),
  ).optional(),
  refusal: z.nullable(z.string()).optional(),
  role: z.literal("assistant"),
  name: z.string().optional(),
  audio: z.nullable(z.lazy(() => CreatePromptMessagesAudio$outboundSchema))
    .optional(),
  toolCalls: z.array(z.lazy(() => CreatePromptMessagesToolCalls$outboundSchema))
    .optional(),
}).transform((v) => {
  return remap$(v, {
    toolCalls: "tool_calls",
  });
});

export function createPromptMessagesAssistantMessageToJSON(
  createPromptMessagesAssistantMessage: CreatePromptMessagesAssistantMessage,
): string {
  return JSON.stringify(
    CreatePromptMessagesAssistantMessage$outboundSchema.parse(
      createPromptMessagesAssistantMessage,
    ),
  );
}

/** @internal */
export const CreatePrompt2PromptsType$outboundSchema: z.ZodNativeEnum<
  typeof CreatePrompt2PromptsType
> = z.nativeEnum(CreatePrompt2PromptsType);

/** @internal */
export const CreatePrompt2Ttl$outboundSchema: z.ZodNativeEnum<
  typeof CreatePrompt2Ttl
> = z.nativeEnum(CreatePrompt2Ttl);

/** @internal */
export type CreatePrompt2CacheControl$Outbound = {
  type: string;
  ttl: string;
};

/** @internal */
export const CreatePrompt2CacheControl$outboundSchema: z.ZodType<
  CreatePrompt2CacheControl$Outbound,
  z.ZodTypeDef,
  CreatePrompt2CacheControl
> = z.object({
  type: CreatePrompt2PromptsType$outboundSchema,
  ttl: CreatePrompt2Ttl$outboundSchema.default("5m"),
});

export function createPrompt2CacheControlToJSON(
  createPrompt2CacheControl: CreatePrompt2CacheControl,
): string {
  return JSON.stringify(
    CreatePrompt2CacheControl$outboundSchema.parse(createPrompt2CacheControl),
  );
}

/** @internal */
export type CreatePrompt24$Outbound = {
  type: "file";
  cache_control?: CreatePrompt2CacheControl$Outbound | undefined;
  file: components.FileContentPartSchema$Outbound;
};

/** @internal */
export const CreatePrompt24$outboundSchema: z.ZodType<
  CreatePrompt24$Outbound,
  z.ZodTypeDef,
  CreatePrompt24
> = z.object({
  type: z.literal("file"),
  cacheControl: z.lazy(() => CreatePrompt2CacheControl$outboundSchema)
    .optional(),
  file: components.FileContentPartSchema$outboundSchema,
}).transform((v) => {
  return remap$(v, {
    cacheControl: "cache_control",
  });
});

export function createPrompt24ToJSON(createPrompt24: CreatePrompt24): string {
  return JSON.stringify(CreatePrompt24$outboundSchema.parse(createPrompt24));
}

/** @internal */
export type CreatePromptContent2$Outbound =
  | (components.TextContentPartSchema$Outbound & { type: "text" })
  | components.ImageContentPartSchema$Outbound
  | components.AudioContentPartSchema$Outbound
  | CreatePrompt24$Outbound;

/** @internal */
export const CreatePromptContent2$outboundSchema: z.ZodType<
  CreatePromptContent2$Outbound,
  z.ZodTypeDef,
  CreatePromptContent2
> = z.union([
  components.TextContentPartSchema$outboundSchema.and(
    z.object({ type: z.literal("text") }),
  ),
  components.ImageContentPartSchema$outboundSchema,
  components.AudioContentPartSchema$outboundSchema,
  z.lazy(() => CreatePrompt24$outboundSchema),
]);

export function createPromptContent2ToJSON(
  createPromptContent2: CreatePromptContent2,
): string {
  return JSON.stringify(
    CreatePromptContent2$outboundSchema.parse(createPromptContent2),
  );
}

/** @internal */
export type CreatePromptMessagesPromptsContent$Outbound =
  | string
  | Array<
    | (components.TextContentPartSchema$Outbound & { type: "text" })
    | components.ImageContentPartSchema$Outbound
    | components.AudioContentPartSchema$Outbound
    | CreatePrompt24$Outbound
  >;

/** @internal */
export const CreatePromptMessagesPromptsContent$outboundSchema: z.ZodType<
  CreatePromptMessagesPromptsContent$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesPromptsContent
> = z.union([
  z.string(),
  z.array(
    z.union([
      components.TextContentPartSchema$outboundSchema.and(
        z.object({ type: z.literal("text") }),
      ),
      components.ImageContentPartSchema$outboundSchema,
      components.AudioContentPartSchema$outboundSchema,
      z.lazy(() => CreatePrompt24$outboundSchema),
    ]),
  ),
]);

export function createPromptMessagesPromptsContentToJSON(
  createPromptMessagesPromptsContent: CreatePromptMessagesPromptsContent,
): string {
  return JSON.stringify(
    CreatePromptMessagesPromptsContent$outboundSchema.parse(
      createPromptMessagesPromptsContent,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesUserMessage$Outbound = {
  role: "user";
  name?: string | undefined;
  content:
    | string
    | Array<
      | (components.TextContentPartSchema$Outbound & { type: "text" })
      | components.ImageContentPartSchema$Outbound
      | components.AudioContentPartSchema$Outbound
      | CreatePrompt24$Outbound
    >;
};

/** @internal */
export const CreatePromptMessagesUserMessage$outboundSchema: z.ZodType<
  CreatePromptMessagesUserMessage$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesUserMessage
> = z.object({
  role: z.literal("user"),
  name: z.string().optional(),
  content: z.union([
    z.string(),
    z.array(
      z.union([
        components.TextContentPartSchema$outboundSchema.and(
          z.object({ type: z.literal("text") }),
        ),
        components.ImageContentPartSchema$outboundSchema,
        components.AudioContentPartSchema$outboundSchema,
        z.lazy(() => CreatePrompt24$outboundSchema),
      ]),
    ),
  ]),
});

export function createPromptMessagesUserMessageToJSON(
  createPromptMessagesUserMessage: CreatePromptMessagesUserMessage,
): string {
  return JSON.stringify(
    CreatePromptMessagesUserMessage$outboundSchema.parse(
      createPromptMessagesUserMessage,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesContent$Outbound =
  | string
  | Array<components.TextContentPartSchema$Outbound>;

/** @internal */
export const CreatePromptMessagesContent$outboundSchema: z.ZodType<
  CreatePromptMessagesContent$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesContent
> = z.union([
  z.string(),
  z.array(components.TextContentPartSchema$outboundSchema),
]);

export function createPromptMessagesContentToJSON(
  createPromptMessagesContent: CreatePromptMessagesContent,
): string {
  return JSON.stringify(
    CreatePromptMessagesContent$outboundSchema.parse(
      createPromptMessagesContent,
    ),
  );
}

/** @internal */
export type CreatePromptMessagesSystemMessage$Outbound = {
  role: "system";
  content: string | Array<components.TextContentPartSchema$Outbound>;
  name?: string | undefined;
};

/** @internal */
export const CreatePromptMessagesSystemMessage$outboundSchema: z.ZodType<
  CreatePromptMessagesSystemMessage$Outbound,
  z.ZodTypeDef,
  CreatePromptMessagesSystemMessage
> = z.object({
  role: z.literal("system"),
  content: z.union([
    z.string(),
    z.array(components.TextContentPartSchema$outboundSchema),
  ]),
  name: z.string().optional(),
});

export function createPromptMessagesSystemMessageToJSON(
  createPromptMessagesSystemMessage: CreatePromptMessagesSystemMessage,
): string {
  return JSON.stringify(
    CreatePromptMessagesSystemMessage$outboundSchema.parse(
      createPromptMessagesSystemMessage,
    ),
  );
}

/** @internal */
export type CreatePromptMessages$Outbound =
  | CreatePromptMessagesSystemMessage$Outbound
  | CreatePromptMessagesUserMessage$Outbound
  | CreatePromptMessagesAssistantMessage$Outbound
  | CreatePromptMessagesToolMessage$Outbound;

/** @internal */
export const CreatePromptMessages$outboundSchema: z.ZodType<
  CreatePromptMessages$Outbound,
  z.ZodTypeDef,
  CreatePromptMessages
> = z.union([
  z.lazy(() => CreatePromptMessagesSystemMessage$outboundSchema),
  z.lazy(() => CreatePromptMessagesUserMessage$outboundSchema),
  z.lazy(() => CreatePromptMessagesAssistantMessage$outboundSchema),
  z.lazy(() => CreatePromptMessagesToolMessage$outboundSchema),
]);

export function createPromptMessagesToJSON(
  createPromptMessages: CreatePromptMessages,
): string {
  return JSON.stringify(
    CreatePromptMessages$outboundSchema.parse(createPromptMessages),
  );
}

/** @internal */
export const CreatePromptVoice$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptVoice
> = z.nativeEnum(CreatePromptVoice);

/** @internal */
export const CreatePromptFormat$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptFormat
> = z.nativeEnum(CreatePromptFormat);

/** @internal */
export type CreatePromptAudio$Outbound = {
  voice: string;
  format: string;
};

/** @internal */
export const CreatePromptAudio$outboundSchema: z.ZodType<
  CreatePromptAudio$Outbound,
  z.ZodTypeDef,
  CreatePromptAudio
> = z.object({
  voice: CreatePromptVoice$outboundSchema,
  format: CreatePromptFormat$outboundSchema,
});

export function createPromptAudioToJSON(
  createPromptAudio: CreatePromptAudio,
): string {
  return JSON.stringify(
    CreatePromptAudio$outboundSchema.parse(createPromptAudio),
  );
}

/** @internal */
export type CreatePromptResponseFormatPromptsJsonSchema$Outbound = {
  description?: string | undefined;
  name: string;
  schema?: any | undefined;
  strict: boolean;
};

/** @internal */
export const CreatePromptResponseFormatPromptsJsonSchema$outboundSchema:
  z.ZodType<
    CreatePromptResponseFormatPromptsJsonSchema$Outbound,
    z.ZodTypeDef,
    CreatePromptResponseFormatPromptsJsonSchema
  > = z.object({
    description: z.string().optional(),
    name: z.string(),
    schema: z.any().optional(),
    strict: z.boolean().default(false),
  });

export function createPromptResponseFormatPromptsJsonSchemaToJSON(
  createPromptResponseFormatPromptsJsonSchema:
    CreatePromptResponseFormatPromptsJsonSchema,
): string {
  return JSON.stringify(
    CreatePromptResponseFormatPromptsJsonSchema$outboundSchema.parse(
      createPromptResponseFormatPromptsJsonSchema,
    ),
  );
}

/** @internal */
export type CreatePromptResponseFormatJSONSchema$Outbound = {
  type: "json_schema";
  json_schema: CreatePromptResponseFormatPromptsJsonSchema$Outbound;
};

/** @internal */
export const CreatePromptResponseFormatJSONSchema$outboundSchema: z.ZodType<
  CreatePromptResponseFormatJSONSchema$Outbound,
  z.ZodTypeDef,
  CreatePromptResponseFormatJSONSchema
> = z.object({
  type: z.literal("json_schema"),
  jsonSchema: z.lazy(() =>
    CreatePromptResponseFormatPromptsJsonSchema$outboundSchema
  ),
}).transform((v) => {
  return remap$(v, {
    jsonSchema: "json_schema",
  });
});

export function createPromptResponseFormatJSONSchemaToJSON(
  createPromptResponseFormatJSONSchema: CreatePromptResponseFormatJSONSchema,
): string {
  return JSON.stringify(
    CreatePromptResponseFormatJSONSchema$outboundSchema.parse(
      createPromptResponseFormatJSONSchema,
    ),
  );
}

/** @internal */
export type CreatePromptResponseFormatJSONObject$Outbound = {
  type: "json_object";
};

/** @internal */
export const CreatePromptResponseFormatJSONObject$outboundSchema: z.ZodType<
  CreatePromptResponseFormatJSONObject$Outbound,
  z.ZodTypeDef,
  CreatePromptResponseFormatJSONObject
> = z.object({
  type: z.literal("json_object"),
});

export function createPromptResponseFormatJSONObjectToJSON(
  createPromptResponseFormatJSONObject: CreatePromptResponseFormatJSONObject,
): string {
  return JSON.stringify(
    CreatePromptResponseFormatJSONObject$outboundSchema.parse(
      createPromptResponseFormatJSONObject,
    ),
  );
}

/** @internal */
export type CreatePromptResponseFormatText$Outbound = {
  type: "text";
};

/** @internal */
export const CreatePromptResponseFormatText$outboundSchema: z.ZodType<
  CreatePromptResponseFormatText$Outbound,
  z.ZodTypeDef,
  CreatePromptResponseFormatText
> = z.object({
  type: z.literal("text"),
});

export function createPromptResponseFormatTextToJSON(
  createPromptResponseFormatText: CreatePromptResponseFormatText,
): string {
  return JSON.stringify(
    CreatePromptResponseFormatText$outboundSchema.parse(
      createPromptResponseFormatText,
    ),
  );
}

/** @internal */
export type CreatePromptResponseFormat$Outbound =
  | CreatePromptResponseFormatText$Outbound
  | CreatePromptResponseFormatJSONObject$Outbound
  | CreatePromptResponseFormatJSONSchema$Outbound;

/** @internal */
export const CreatePromptResponseFormat$outboundSchema: z.ZodType<
  CreatePromptResponseFormat$Outbound,
  z.ZodTypeDef,
  CreatePromptResponseFormat
> = z.union([
  z.lazy(() => CreatePromptResponseFormatText$outboundSchema),
  z.lazy(() => CreatePromptResponseFormatJSONObject$outboundSchema),
  z.lazy(() => CreatePromptResponseFormatJSONSchema$outboundSchema),
]);

export function createPromptResponseFormatToJSON(
  createPromptResponseFormat: CreatePromptResponseFormat,
): string {
  return JSON.stringify(
    CreatePromptResponseFormat$outboundSchema.parse(createPromptResponseFormat),
  );
}

/** @internal */
export const CreatePromptReasoningEffort$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptReasoningEffort
> = z.nativeEnum(CreatePromptReasoningEffort);

/** @internal */
export type CreatePromptStop$Outbound = string | Array<string>;

/** @internal */
export const CreatePromptStop$outboundSchema: z.ZodType<
  CreatePromptStop$Outbound,
  z.ZodTypeDef,
  CreatePromptStop
> = z.union([z.string(), z.array(z.string())]);

export function createPromptStopToJSON(
  createPromptStop: CreatePromptStop,
): string {
  return JSON.stringify(
    CreatePromptStop$outboundSchema.parse(createPromptStop),
  );
}

/** @internal */
export type CreatePromptStreamOptions$Outbound = {
  include_usage?: boolean | undefined;
};

/** @internal */
export const CreatePromptStreamOptions$outboundSchema: z.ZodType<
  CreatePromptStreamOptions$Outbound,
  z.ZodTypeDef,
  CreatePromptStreamOptions
> = z.object({
  includeUsage: z.boolean().optional(),
}).transform((v) => {
  return remap$(v, {
    includeUsage: "include_usage",
  });
});

export function createPromptStreamOptionsToJSON(
  createPromptStreamOptions: CreatePromptStreamOptions,
): string {
  return JSON.stringify(
    CreatePromptStreamOptions$outboundSchema.parse(createPromptStreamOptions),
  );
}

/** @internal */
export type CreatePromptThinking$Outbound =
  | components.ThinkingConfigDisabledSchema$Outbound
  | components.ThinkingConfigEnabledSchema$Outbound;

/** @internal */
export const CreatePromptThinking$outboundSchema: z.ZodType<
  CreatePromptThinking$Outbound,
  z.ZodTypeDef,
  CreatePromptThinking
> = z.union([
  components.ThinkingConfigDisabledSchema$outboundSchema,
  components.ThinkingConfigEnabledSchema$outboundSchema,
]);

export function createPromptThinkingToJSON(
  createPromptThinking: CreatePromptThinking,
): string {
  return JSON.stringify(
    CreatePromptThinking$outboundSchema.parse(createPromptThinking),
  );
}

/** @internal */
export const CreatePromptToolChoiceType$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptToolChoiceType
> = z.nativeEnum(CreatePromptToolChoiceType);

/** @internal */
export type CreatePromptToolChoiceFunction$Outbound = {
  name: string;
};

/** @internal */
export const CreatePromptToolChoiceFunction$outboundSchema: z.ZodType<
  CreatePromptToolChoiceFunction$Outbound,
  z.ZodTypeDef,
  CreatePromptToolChoiceFunction
> = z.object({
  name: z.string(),
});

export function createPromptToolChoiceFunctionToJSON(
  createPromptToolChoiceFunction: CreatePromptToolChoiceFunction,
): string {
  return JSON.stringify(
    CreatePromptToolChoiceFunction$outboundSchema.parse(
      createPromptToolChoiceFunction,
    ),
  );
}

/** @internal */
export type CreatePromptToolChoice2$Outbound = {
  type?: string | undefined;
  function: CreatePromptToolChoiceFunction$Outbound;
};

/** @internal */
export const CreatePromptToolChoice2$outboundSchema: z.ZodType<
  CreatePromptToolChoice2$Outbound,
  z.ZodTypeDef,
  CreatePromptToolChoice2
> = z.object({
  type: CreatePromptToolChoiceType$outboundSchema.optional(),
  function: z.lazy(() => CreatePromptToolChoiceFunction$outboundSchema),
});

export function createPromptToolChoice2ToJSON(
  createPromptToolChoice2: CreatePromptToolChoice2,
): string {
  return JSON.stringify(
    CreatePromptToolChoice2$outboundSchema.parse(createPromptToolChoice2),
  );
}

/** @internal */
export const CreatePromptToolChoice1$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptToolChoice1
> = z.nativeEnum(CreatePromptToolChoice1);

/** @internal */
export type CreatePromptToolChoice$Outbound =
  | CreatePromptToolChoice2$Outbound
  | string;

/** @internal */
export const CreatePromptToolChoice$outboundSchema: z.ZodType<
  CreatePromptToolChoice$Outbound,
  z.ZodTypeDef,
  CreatePromptToolChoice
> = z.union([
  z.lazy(() => CreatePromptToolChoice2$outboundSchema),
  CreatePromptToolChoice1$outboundSchema,
]);

export function createPromptToolChoiceToJSON(
  createPromptToolChoice: CreatePromptToolChoice,
): string {
  return JSON.stringify(
    CreatePromptToolChoice$outboundSchema.parse(createPromptToolChoice),
  );
}

/** @internal */
export const CreatePromptModalities$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptModalities
> = z.nativeEnum(CreatePromptModalities);

/** @internal */
export const CreatePromptId1$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptId1
> = z.nativeEnum(CreatePromptId1);

/** @internal */
export type CreatePromptId$Outbound = string | string;

/** @internal */
export const CreatePromptId$outboundSchema: z.ZodType<
  CreatePromptId$Outbound,
  z.ZodTypeDef,
  CreatePromptId
> = z.union([CreatePromptId1$outboundSchema, z.string()]);

export function createPromptIdToJSON(createPromptId: CreatePromptId): string {
  return JSON.stringify(CreatePromptId$outboundSchema.parse(createPromptId));
}

/** @internal */
export const CreatePromptExecuteOn$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptExecuteOn
> = z.nativeEnum(CreatePromptExecuteOn);

/** @internal */
export type CreatePromptGuardrails$Outbound = {
  id: string | string;
  execute_on: string;
};

/** @internal */
export const CreatePromptGuardrails$outboundSchema: z.ZodType<
  CreatePromptGuardrails$Outbound,
  z.ZodTypeDef,
  CreatePromptGuardrails
> = z.object({
  id: z.union([CreatePromptId1$outboundSchema, z.string()]),
  executeOn: CreatePromptExecuteOn$outboundSchema,
}).transform((v) => {
  return remap$(v, {
    executeOn: "execute_on",
  });
});

export function createPromptGuardrailsToJSON(
  createPromptGuardrails: CreatePromptGuardrails,
): string {
  return JSON.stringify(
    CreatePromptGuardrails$outboundSchema.parse(createPromptGuardrails),
  );
}

/** @internal */
export type CreatePromptFallbacks$Outbound = {
  model: string;
};

/** @internal */
export const CreatePromptFallbacks$outboundSchema: z.ZodType<
  CreatePromptFallbacks$Outbound,
  z.ZodTypeDef,
  CreatePromptFallbacks
> = z.object({
  model: z.string(),
});

export function createPromptFallbacksToJSON(
  createPromptFallbacks: CreatePromptFallbacks,
): string {
  return JSON.stringify(
    CreatePromptFallbacks$outboundSchema.parse(createPromptFallbacks),
  );
}

/** @internal */
export type CreatePromptRetry$Outbound = {
  count: number;
  on_codes?: Array<number> | undefined;
};

/** @internal */
export const CreatePromptRetry$outboundSchema: z.ZodType<
  CreatePromptRetry$Outbound,
  z.ZodTypeDef,
  CreatePromptRetry
> = z.object({
  count: z.number().default(3),
  onCodes: z.array(z.number()).optional(),
}).transform((v) => {
  return remap$(v, {
    onCodes: "on_codes",
  });
});

export function createPromptRetryToJSON(
  createPromptRetry: CreatePromptRetry,
): string {
  return JSON.stringify(
    CreatePromptRetry$outboundSchema.parse(createPromptRetry),
  );
}

/** @internal */
export const CreatePromptType$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptType
> = z.nativeEnum(CreatePromptType);

/** @internal */
export type CreatePromptCache$Outbound = {
  ttl: number;
  type: string;
};

/** @internal */
export const CreatePromptCache$outboundSchema: z.ZodType<
  CreatePromptCache$Outbound,
  z.ZodTypeDef,
  CreatePromptCache
> = z.object({
  ttl: z.number().default(1800),
  type: CreatePromptType$outboundSchema,
});

export function createPromptCacheToJSON(
  createPromptCache: CreatePromptCache,
): string {
  return JSON.stringify(
    CreatePromptCache$outboundSchema.parse(createPromptCache),
  );
}

/** @internal */
export const CreatePromptLoadBalancerType$outboundSchema: z.ZodNativeEnum<
  typeof CreatePromptLoadBalancerType
> = z.nativeEnum(CreatePromptLoadBalancerType);

/** @internal */
export type CreatePromptLoadBalancer1$Outbound = {
  type: string;
  model: string;
  weight: number;
};

/** @internal */
export const CreatePromptLoadBalancer1$outboundSchema: z.ZodType<
  CreatePromptLoadBalancer1$Outbound,
  z.ZodTypeDef,
  CreatePromptLoadBalancer1
> = z.object({
  type: CreatePromptLoadBalancerType$outboundSchema,
  model: z.string(),
  weight: z.number().default(0.5),
});

export function createPromptLoadBalancer1ToJSON(
  createPromptLoadBalancer1: CreatePromptLoadBalancer1,
): string {
  return JSON.stringify(
    CreatePromptLoadBalancer1$outboundSchema.parse(createPromptLoadBalancer1),
  );
}

/** @internal */
export type CreatePromptLoadBalancer$Outbound =
  CreatePromptLoadBalancer1$Outbound;

/** @internal */
export const CreatePromptLoadBalancer$outboundSchema: z.ZodType<
  CreatePromptLoadBalancer$Outbound,
  z.ZodTypeDef,
  CreatePromptLoadBalancer
> = z.lazy(() => CreatePromptLoadBalancer1$outboundSchema);

export function createPromptLoadBalancerToJSON(
  createPromptLoadBalancer: CreatePromptLoadBalancer,
): string {
  return JSON.stringify(
    CreatePromptLoadBalancer$outboundSchema.parse(createPromptLoadBalancer),
  );
}

/** @internal */
export type CreatePromptTimeout$Outbound = {
  call_timeout: number;
};

/** @internal */
export const CreatePromptTimeout$outboundSchema: z.ZodType<
  CreatePromptTimeout$Outbound,
  z.ZodTypeDef,
  CreatePromptTimeout
> = z.object({
  callTimeout: z.number(),
}).transform((v) => {
  return remap$(v, {
    callTimeout: "call_timeout",
  });
});

export function createPromptTimeoutToJSON(
  createPromptTimeout: CreatePromptTimeout,
): string {
  return JSON.stringify(
    CreatePromptTimeout$outboundSchema.parse(createPromptTimeout),
  );
}

/** @internal */
export type PromptInput$Outbound = {
  messages: Array<
    | CreatePromptMessagesSystemMessage$Outbound
    | CreatePromptMessagesUserMessage$Outbound
    | CreatePromptMessagesAssistantMessage$Outbound
    | CreatePromptMessagesToolMessage$Outbound
  >;
  model?: string | undefined;
  audio?: CreatePromptAudio$Outbound | null | undefined;
  frequency_penalty?: number | null | undefined;
  max_tokens?: number | null | undefined;
  max_completion_tokens?: number | null | undefined;
  logprobs?: boolean | null | undefined;
  top_logprobs?: number | null | undefined;
  n?: number | null | undefined;
  presence_penalty?: number | null | undefined;
  response_format?:
    | CreatePromptResponseFormatText$Outbound
    | CreatePromptResponseFormatJSONObject$Outbound
    | CreatePromptResponseFormatJSONSchema$Outbound
    | undefined;
  reasoning_effort?: string | undefined;
  verbosity?: string | undefined;
  seed?: number | null | undefined;
  stop?: string | Array<string> | null | undefined;
  stream_options?: CreatePromptStreamOptions$Outbound | null | undefined;
  thinking?:
    | components.ThinkingConfigDisabledSchema$Outbound
    | components.ThinkingConfigEnabledSchema$Outbound
    | undefined;
  temperature?: number | null | undefined;
  top_p?: number | null | undefined;
  top_k?: number | null | undefined;
  tool_choice?: CreatePromptToolChoice2$Outbound | string | undefined;
  parallel_tool_calls?: boolean | undefined;
  modalities?: Array<string> | null | undefined;
  guardrails?: Array<CreatePromptGuardrails$Outbound> | undefined;
  fallbacks?: Array<CreatePromptFallbacks$Outbound> | undefined;
  retry?: CreatePromptRetry$Outbound | undefined;
  cache?: CreatePromptCache$Outbound | undefined;
  load_balancer?: Array<CreatePromptLoadBalancer1$Outbound> | undefined;
  timeout?: CreatePromptTimeout$Outbound | undefined;
};

/** @internal */
export const PromptInput$outboundSchema: z.ZodType<
  PromptInput$Outbound,
  z.ZodTypeDef,
  PromptInput
> = z.object({
  messages: z.array(
    z.union([
      z.lazy(() => CreatePromptMessagesSystemMessage$outboundSchema),
      z.lazy(() => CreatePromptMessagesUserMessage$outboundSchema),
      z.lazy(() => CreatePromptMessagesAssistantMessage$outboundSchema),
      z.lazy(() => CreatePromptMessagesToolMessage$outboundSchema),
    ]),
  ),
  model: z.string().optional(),
  audio: z.nullable(z.lazy(() => CreatePromptAudio$outboundSchema)).optional(),
  frequencyPenalty: z.nullable(z.number()).optional(),
  maxTokens: z.nullable(z.number().int()).optional(),
  maxCompletionTokens: z.nullable(z.number().int()).optional(),
  logprobs: z.nullable(z.boolean()).optional(),
  topLogprobs: z.nullable(z.number().int()).optional(),
  n: z.nullable(z.number().int()).optional(),
  presencePenalty: z.nullable(z.number()).optional(),
  responseFormat: z.union([
    z.lazy(() => CreatePromptResponseFormatText$outboundSchema),
    z.lazy(() => CreatePromptResponseFormatJSONObject$outboundSchema),
    z.lazy(() => CreatePromptResponseFormatJSONSchema$outboundSchema),
  ]).optional(),
  reasoningEffort: CreatePromptReasoningEffort$outboundSchema.optional(),
  verbosity: z.string().optional(),
  seed: z.nullable(z.number()).optional(),
  stop: z.nullable(z.union([z.string(), z.array(z.string())])).optional(),
  streamOptions: z.nullable(
    z.lazy(() => CreatePromptStreamOptions$outboundSchema),
  ).optional(),
  thinking: z.union([
    components.ThinkingConfigDisabledSchema$outboundSchema,
    components.ThinkingConfigEnabledSchema$outboundSchema,
  ]).optional(),
  temperature: z.nullable(z.number()).optional(),
  topP: z.nullable(z.number()).optional(),
  topK: z.nullable(z.number()).optional(),
  toolChoice: z.union([
    z.lazy(() => CreatePromptToolChoice2$outboundSchema),
    CreatePromptToolChoice1$outboundSchema,
  ]).optional(),
  parallelToolCalls: z.boolean().optional(),
  modalities: z.nullable(z.array(CreatePromptModalities$outboundSchema))
    .optional(),
  guardrails: z.array(z.lazy(() => CreatePromptGuardrails$outboundSchema))
    .optional(),
  fallbacks: z.array(z.lazy(() => CreatePromptFallbacks$outboundSchema))
    .optional(),
  retry: z.lazy(() => CreatePromptRetry$outboundSchema).optional(),
  cache: z.lazy(() => CreatePromptCache$outboundSchema).optional(),
  loadBalancer: z.array(z.lazy(() => CreatePromptLoadBalancer1$outboundSchema))
    .optional(),
  timeout: z.lazy(() => CreatePromptTimeout$outboundSchema).optional(),
}).transform((v) => {
  return remap$(v, {
    frequencyPenalty: "frequency_penalty",
    maxTokens: "max_tokens",
    maxCompletionTokens: "max_completion_tokens",
    topLogprobs: "top_logprobs",
    presencePenalty: "presence_penalty",
    responseFormat: "response_format",
    reasoningEffort: "reasoning_effort",
    streamOptions: "stream_options",
    topP: "top_p",
    topK: "top_k",
    toolChoice: "tool_choice",
    parallelToolCalls: "parallel_tool_calls",
    loadBalancer: "load_balancer",
  });
});

export function promptInputToJSON(promptInput: PromptInput): string {
  return JSON.stringify(PromptInput$outboundSchema.parse(promptInput));
}

/** @internal */
export type CreatePromptRequestBody$Outbound = {
  display_name: string;
  description?: string | null | undefined;
  metadata?: CreatePromptMetadata$Outbound | undefined;
  prompt?: PromptInput$Outbound | undefined;
  path: string;
};

/** @internal */
export const CreatePromptRequestBody$outboundSchema: z.ZodType<
  CreatePromptRequestBody$Outbound,
  z.ZodTypeDef,
  CreatePromptRequestBody
> = z.object({
  displayName: z.string(),
  description: z.nullable(z.string()).optional(),
  metadata: z.lazy(() => CreatePromptMetadata$outboundSchema).optional(),
  prompt: z.lazy(() => PromptInput$outboundSchema).optional(),
  path: z.string(),
}).transform((v) => {
  return remap$(v, {
    displayName: "display_name",
  });
});

export function createPromptRequestBodyToJSON(
  createPromptRequestBody: CreatePromptRequestBody,
): string {
  return JSON.stringify(
    CreatePromptRequestBody$outboundSchema.parse(createPromptRequestBody),
  );
}

/** @internal */
export const CreatePromptPromptsType$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsType
> = z.nativeEnum(CreatePromptPromptsType);

/** @internal */
export const ModelType$inboundSchema: z.ZodNativeEnum<typeof ModelType> = z
  .nativeEnum(ModelType);

/** @internal */
export const CreatePromptPromptsFormat$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsFormat
> = z.nativeEnum(CreatePromptPromptsFormat);

/** @internal */
export const CreatePromptResponseFormat6$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptResponseFormat6
> = z.nativeEnum(CreatePromptResponseFormat6);

/** @internal */
export const CreatePromptResponseFormat5$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptResponseFormat5
> = z.nativeEnum(CreatePromptResponseFormat5);

/** @internal */
export const CreatePromptResponseFormat4$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptResponseFormat4
> = z.nativeEnum(CreatePromptResponseFormat4);

/** @internal */
export const CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigModelParametersType$inboundSchema:
  z.ZodNativeEnum<
    typeof CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigModelParametersType
  > = z.nativeEnum(
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigModelParametersType,
  );

/** @internal */
export const CreatePromptResponseFormat3$inboundSchema: z.ZodType<
  CreatePromptResponseFormat3,
  z.ZodTypeDef,
  unknown
> = z.object({
  type:
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigModelParametersType$inboundSchema,
});

export function createPromptResponseFormat3FromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptResponseFormat3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptResponseFormat3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptResponseFormat3' from JSON`,
  );
}

/** @internal */
export const CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigType$inboundSchema:
  z.ZodNativeEnum<
    typeof CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigType
  > = z.nativeEnum(
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigType,
  );

/** @internal */
export const CreatePromptResponseFormat2$inboundSchema: z.ZodType<
  CreatePromptResponseFormat2,
  z.ZodTypeDef,
  unknown
> = z.object({
  type:
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyPromptConfigType$inboundSchema,
});

export function createPromptResponseFormat2FromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptResponseFormat2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptResponseFormat2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptResponseFormat2' from JSON`,
  );
}

/** @internal */
export const CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyType$inboundSchema:
  z.ZodNativeEnum<
    typeof CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyType
  > = z.nativeEnum(
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyType,
  );

/** @internal */
export const CreatePromptResponseFormatPromptsResponse200ApplicationJSONJSONSchema$inboundSchema:
  z.ZodType<
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONJSONSchema,
    z.ZodTypeDef,
    unknown
  > = z.object({
    name: z.string(),
    description: z.string().optional(),
    strict: z.boolean().optional(),
    schema: z.record(z.any()),
  });

export function createPromptResponseFormatPromptsResponse200ApplicationJSONJSONSchemaFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptResponseFormatPromptsResponse200ApplicationJSONJSONSchema,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptResponseFormatPromptsResponse200ApplicationJSONJSONSchema$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptResponseFormatPromptsResponse200ApplicationJSONJSONSchema' from JSON`,
  );
}

/** @internal */
export const CreatePromptResponseFormat1$inboundSchema: z.ZodType<
  CreatePromptResponseFormat1,
  z.ZodTypeDef,
  unknown
> = z.object({
  type:
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONResponseBodyType$inboundSchema,
  display_name: z.string().optional(),
  json_schema: z.lazy(() =>
    CreatePromptResponseFormatPromptsResponse200ApplicationJSONJSONSchema$inboundSchema
  ),
}).transform((v) => {
  return remap$(v, {
    "display_name": "displayName",
    "json_schema": "jsonSchema",
  });
});

export function createPromptResponseFormat1FromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptResponseFormat1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptResponseFormat1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptResponseFormat1' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsResponseResponseFormat$inboundSchema: z.ZodType<
  CreatePromptPromptsResponseResponseFormat,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => CreatePromptResponseFormat1$inboundSchema),
  z.lazy(() => CreatePromptResponseFormat2$inboundSchema),
  z.lazy(() => CreatePromptResponseFormat3$inboundSchema),
  CreatePromptResponseFormat4$inboundSchema,
  CreatePromptResponseFormat5$inboundSchema,
  CreatePromptResponseFormat6$inboundSchema,
]);

export function createPromptPromptsResponseResponseFormatFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptPromptsResponseResponseFormat,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptPromptsResponseResponseFormat$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptPromptsResponseResponseFormat' from JSON`,
  );
}

/** @internal */
export const CreatePromptPhotoRealVersion$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPhotoRealVersion
> = z.nativeEnum(CreatePromptPhotoRealVersion);

/** @internal */
export const CreatePromptEncodingFormat$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptEncodingFormat
> = z.nativeEnum(CreatePromptEncodingFormat);

/** @internal */
export const CreatePromptPromptsResponseReasoningEffort$inboundSchema:
  z.ZodNativeEnum<typeof CreatePromptPromptsResponseReasoningEffort> = z
    .nativeEnum(CreatePromptPromptsResponseReasoningEffort);

/** @internal */
export const CreatePromptVerbosity$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptVerbosity
> = z.nativeEnum(CreatePromptVerbosity);

/** @internal */
export const CreatePromptThinkingLevel$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptThinkingLevel
> = z.nativeEnum(CreatePromptThinkingLevel);

/** @internal */
export const ModelParameters$inboundSchema: z.ZodType<
  ModelParameters,
  z.ZodTypeDef,
  unknown
> = z.object({
  temperature: z.number().optional(),
  maxTokens: z.number().optional(),
  topK: z.number().optional(),
  topP: z.number().optional(),
  frequencyPenalty: z.number().optional(),
  presencePenalty: z.number().optional(),
  numImages: z.number().optional(),
  seed: z.number().optional(),
  format: CreatePromptPromptsFormat$inboundSchema.optional(),
  dimensions: z.string().optional(),
  quality: z.string().optional(),
  style: z.string().optional(),
  responseFormat: z.nullable(
    z.union([
      z.lazy(() => CreatePromptResponseFormat1$inboundSchema),
      z.lazy(() => CreatePromptResponseFormat2$inboundSchema),
      z.lazy(() => CreatePromptResponseFormat3$inboundSchema),
      CreatePromptResponseFormat4$inboundSchema,
      CreatePromptResponseFormat5$inboundSchema,
      CreatePromptResponseFormat6$inboundSchema,
    ]),
  ).optional(),
  photoRealVersion: CreatePromptPhotoRealVersion$inboundSchema.optional(),
  encoding_format: CreatePromptEncodingFormat$inboundSchema.optional(),
  reasoningEffort: CreatePromptPromptsResponseReasoningEffort$inboundSchema
    .optional(),
  budgetTokens: z.number().optional(),
  verbosity: CreatePromptVerbosity$inboundSchema.optional(),
  thinkingLevel: CreatePromptThinkingLevel$inboundSchema.optional(),
}).transform((v) => {
  return remap$(v, {
    "encoding_format": "encodingFormat",
  });
});

export function modelParametersFromJSON(
  jsonString: string,
): SafeParseResult<ModelParameters, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ModelParameters$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ModelParameters' from JSON`,
  );
}

/** @internal */
export const CreatePromptProvider$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptProvider
> = z.nativeEnum(CreatePromptProvider);

/** @internal */
export const CreatePromptRole$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptRole
> = z.nativeEnum(CreatePromptRole);

/** @internal */
export const CreatePrompt2File$inboundSchema: z.ZodType<
  CreatePrompt2File,
  z.ZodTypeDef,
  unknown
> = z.object({
  file_data: z.string().optional(),
  uri: z.string().optional(),
  mimeType: z.string().optional(),
  filename: z.string().optional(),
}).transform((v) => {
  return remap$(v, {
    "file_data": "fileData",
  });
});

export function createPrompt2FileFromJSON(
  jsonString: string,
): SafeParseResult<CreatePrompt2File, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePrompt2File$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePrompt2File' from JSON`,
  );
}

/** @internal */
export const CreatePrompt23$inboundSchema: z.ZodType<
  CreatePrompt23,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: z.literal("file"),
  file: z.lazy(() => CreatePrompt2File$inboundSchema),
});

export function createPrompt23FromJSON(
  jsonString: string,
): SafeParseResult<CreatePrompt23, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePrompt23$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePrompt23' from JSON`,
  );
}

/** @internal */
export const CreatePrompt2ImageUrl$inboundSchema: z.ZodType<
  CreatePrompt2ImageUrl,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string().optional(),
  url: z.string(),
  detail: z.string().optional(),
});

export function createPrompt2ImageUrlFromJSON(
  jsonString: string,
): SafeParseResult<CreatePrompt2ImageUrl, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePrompt2ImageUrl$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePrompt2ImageUrl' from JSON`,
  );
}

/** @internal */
export const CreatePrompt22$inboundSchema: z.ZodType<
  CreatePrompt22,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: z.literal("image_url"),
  image_url: z.lazy(() => CreatePrompt2ImageUrl$inboundSchema),
}).transform((v) => {
  return remap$(v, {
    "image_url": "imageUrl",
  });
});

export function createPrompt22FromJSON(
  jsonString: string,
): SafeParseResult<CreatePrompt22, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePrompt22$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePrompt22' from JSON`,
  );
}

/** @internal */
export const CreatePrompt21$inboundSchema: z.ZodType<
  CreatePrompt21,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: z.literal("text"),
  text: z.string(),
});

export function createPrompt21FromJSON(
  jsonString: string,
): SafeParseResult<CreatePrompt21, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePrompt21$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePrompt21' from JSON`,
  );
}

/** @internal */
export const CreatePromptContentPromptsResponse2$inboundSchema: z.ZodType<
  CreatePromptContentPromptsResponse2,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => CreatePrompt21$inboundSchema),
  z.lazy(() => CreatePrompt22$inboundSchema),
  z.lazy(() => CreatePrompt23$inboundSchema),
]);

export function createPromptContentPromptsResponse2FromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptContentPromptsResponse2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptContentPromptsResponse2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptContentPromptsResponse2' from JSON`,
  );
}

/** @internal */
export const CreatePromptContent$inboundSchema: z.ZodType<
  CreatePromptContent,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.string(),
  z.array(z.union([
    z.lazy(() => CreatePrompt21$inboundSchema),
    z.lazy(() => CreatePrompt22$inboundSchema),
    z.lazy(() => CreatePrompt23$inboundSchema),
  ])),
]);

export function createPromptContentFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptContent, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptContent$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptContent' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsResponse200Type$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsResponse200Type
> = z.nativeEnum(CreatePromptPromptsResponse200Type);

/** @internal */
export const CreatePromptFunction$inboundSchema: z.ZodType<
  CreatePromptFunction,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  arguments: z.string(),
});

export function createPromptFunctionFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptFunction, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptFunction$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptFunction' from JSON`,
  );
}

/** @internal */
export const CreatePromptToolCalls$inboundSchema: z.ZodType<
  CreatePromptToolCalls,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string().optional(),
  index: z.number().optional(),
  type: CreatePromptPromptsResponse200Type$inboundSchema,
  function: z.lazy(() => CreatePromptFunction$inboundSchema),
});

export function createPromptToolCallsFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptToolCalls, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptToolCalls$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptToolCalls' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsMessages$inboundSchema: z.ZodType<
  CreatePromptPromptsMessages,
  z.ZodTypeDef,
  unknown
> = z.object({
  role: CreatePromptRole$inboundSchema,
  content: z.nullable(
    z.union([
      z.string(),
      z.array(z.union([
        z.lazy(() => CreatePrompt21$inboundSchema),
        z.lazy(() => CreatePrompt22$inboundSchema),
        z.lazy(() => CreatePrompt23$inboundSchema),
      ])),
    ]),
  ),
  tool_calls: z.array(z.lazy(() => CreatePromptToolCalls$inboundSchema))
    .optional(),
  tool_call_id: z.nullable(z.string()).optional(),
}).transform((v) => {
  return remap$(v, {
    "tool_calls": "toolCalls",
    "tool_call_id": "toolCallId",
  });
});

export function createPromptPromptsMessagesFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsMessages, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsMessages$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsMessages' from JSON`,
  );
}

/** @internal */
export const PromptConfig$inboundSchema: z.ZodType<
  PromptConfig,
  z.ZodTypeDef,
  unknown
> = z.object({
  stream: z.boolean().optional(),
  model: z.nullable(z.string()).optional(),
  model_db_id: z.nullable(z.string()).optional(),
  model_type: z.nullable(ModelType$inboundSchema).optional(),
  model_parameters: z.lazy(() => ModelParameters$inboundSchema).optional(),
  provider: z.nullable(CreatePromptProvider$inboundSchema).optional(),
  integration_id: z.nullable(z.string()).optional(),
  version: z.string().optional(),
  messages: z.array(z.lazy(() => CreatePromptPromptsMessages$inboundSchema)),
}).transform((v) => {
  return remap$(v, {
    "model_db_id": "modelDbId",
    "model_type": "modelType",
    "model_parameters": "modelParameters",
    "integration_id": "integrationId",
  });
});

export function promptConfigFromJSON(
  jsonString: string,
): SafeParseResult<PromptConfig, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PromptConfig$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PromptConfig' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsVoice$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsVoice
> = z.nativeEnum(CreatePromptPromptsVoice);

/** @internal */
export const CreatePromptPromptsResponse200Format$inboundSchema:
  z.ZodNativeEnum<typeof CreatePromptPromptsResponse200Format> = z.nativeEnum(
    CreatePromptPromptsResponse200Format,
  );

/** @internal */
export const CreatePromptPromptsAudio$inboundSchema: z.ZodType<
  CreatePromptPromptsAudio,
  z.ZodTypeDef,
  unknown
> = z.object({
  voice: CreatePromptPromptsVoice$inboundSchema,
  format: CreatePromptPromptsResponse200Format$inboundSchema,
});

export function createPromptPromptsAudioFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsAudio, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsAudio$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsAudio' from JSON`,
  );
}

/** @internal */
export const CreatePromptResponseFormatPromptsResponseJsonSchema$inboundSchema:
  z.ZodType<
    CreatePromptResponseFormatPromptsResponseJsonSchema,
    z.ZodTypeDef,
    unknown
  > = z.object({
    description: z.string().optional(),
    name: z.string(),
    schema: z.any().optional(),
    strict: z.boolean().default(false),
  });

export function createPromptResponseFormatPromptsResponseJsonSchemaFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptResponseFormatPromptsResponseJsonSchema,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptResponseFormatPromptsResponseJsonSchema$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptResponseFormatPromptsResponseJsonSchema' from JSON`,
  );
}

/** @internal */
export const CreatePromptResponseFormatPromptsResponse200JSONSchema$inboundSchema:
  z.ZodType<
    CreatePromptResponseFormatPromptsResponse200JSONSchema,
    z.ZodTypeDef,
    unknown
  > = z.object({
    type: z.literal("json_schema"),
    json_schema: z.lazy(() =>
      CreatePromptResponseFormatPromptsResponseJsonSchema$inboundSchema
    ),
  }).transform((v) => {
    return remap$(v, {
      "json_schema": "jsonSchema",
    });
  });

export function createPromptResponseFormatPromptsResponse200JSONSchemaFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptResponseFormatPromptsResponse200JSONSchema,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptResponseFormatPromptsResponse200JSONSchema$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptResponseFormatPromptsResponse200JSONSchema' from JSON`,
  );
}

/** @internal */
export const CreatePromptResponseFormatPromptsJSONObject$inboundSchema:
  z.ZodType<
    CreatePromptResponseFormatPromptsJSONObject,
    z.ZodTypeDef,
    unknown
  > = z.object({
    type: z.literal("json_object"),
  });

export function createPromptResponseFormatPromptsJSONObjectFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptResponseFormatPromptsJSONObject,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptResponseFormatPromptsJSONObject$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptResponseFormatPromptsJSONObject' from JSON`,
  );
}

/** @internal */
export const CreatePromptResponseFormatPromptsText$inboundSchema: z.ZodType<
  CreatePromptResponseFormatPromptsText,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: z.literal("text"),
});

export function createPromptResponseFormatPromptsTextFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptResponseFormatPromptsText, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptResponseFormatPromptsText$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptResponseFormatPromptsText' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsResponseFormat$inboundSchema: z.ZodType<
  CreatePromptPromptsResponseFormat,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => CreatePromptResponseFormatPromptsText$inboundSchema),
  z.lazy(() => CreatePromptResponseFormatPromptsJSONObject$inboundSchema),
  z.lazy(() =>
    CreatePromptResponseFormatPromptsResponse200JSONSchema$inboundSchema
  ),
]);

export function createPromptPromptsResponseFormatFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsResponseFormat, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsResponseFormat$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsResponseFormat' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsReasoningEffort$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsReasoningEffort
> = z.nativeEnum(CreatePromptPromptsReasoningEffort);

/** @internal */
export const CreatePromptPromptsStop$inboundSchema: z.ZodType<
  CreatePromptPromptsStop,
  z.ZodTypeDef,
  unknown
> = z.union([z.string(), z.array(z.string())]);

export function createPromptPromptsStopFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsStop, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsStop$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsStop' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsStreamOptions$inboundSchema: z.ZodType<
  CreatePromptPromptsStreamOptions,
  z.ZodTypeDef,
  unknown
> = z.object({
  include_usage: z.boolean().optional(),
}).transform((v) => {
  return remap$(v, {
    "include_usage": "includeUsage",
  });
});

export function createPromptPromptsStreamOptionsFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsStreamOptions, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsStreamOptions$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsStreamOptions' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsThinking$inboundSchema: z.ZodType<
  CreatePromptPromptsThinking,
  z.ZodTypeDef,
  unknown
> = z.union([
  components.ThinkingConfigDisabledSchema$inboundSchema,
  components.ThinkingConfigEnabledSchema$inboundSchema,
]);

export function createPromptPromptsThinkingFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsThinking, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsThinking$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsThinking' from JSON`,
  );
}

/** @internal */
export const CreatePromptToolChoicePromptsType$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptToolChoicePromptsType
> = z.nativeEnum(CreatePromptToolChoicePromptsType);

/** @internal */
export const CreatePromptToolChoicePromptsFunction$inboundSchema: z.ZodType<
  CreatePromptToolChoicePromptsFunction,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
});

export function createPromptToolChoicePromptsFunctionFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptToolChoicePromptsFunction, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptToolChoicePromptsFunction$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptToolChoicePromptsFunction' from JSON`,
  );
}

/** @internal */
export const CreatePromptToolChoicePrompts2$inboundSchema: z.ZodType<
  CreatePromptToolChoicePrompts2,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: CreatePromptToolChoicePromptsType$inboundSchema.optional(),
  function: z.lazy(() => CreatePromptToolChoicePromptsFunction$inboundSchema),
});

export function createPromptToolChoicePrompts2FromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptToolChoicePrompts2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptToolChoicePrompts2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptToolChoicePrompts2' from JSON`,
  );
}

/** @internal */
export const CreatePromptToolChoicePrompts1$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptToolChoicePrompts1
> = z.nativeEnum(CreatePromptToolChoicePrompts1);

/** @internal */
export const CreatePromptPromptsToolChoice$inboundSchema: z.ZodType<
  CreatePromptPromptsToolChoice,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => CreatePromptToolChoicePrompts2$inboundSchema),
  CreatePromptToolChoicePrompts1$inboundSchema,
]);

export function createPromptPromptsToolChoiceFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsToolChoice, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsToolChoice$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsToolChoice' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsModalities$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsModalities
> = z.nativeEnum(CreatePromptPromptsModalities);

/** @internal */
export const CreatePromptIdPrompts1$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptIdPrompts1
> = z.nativeEnum(CreatePromptIdPrompts1);

/** @internal */
export const CreatePromptPromptsId$inboundSchema: z.ZodType<
  CreatePromptPromptsId,
  z.ZodTypeDef,
  unknown
> = z.union([CreatePromptIdPrompts1$inboundSchema, z.string()]);

export function createPromptPromptsIdFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsId, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsId$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsId' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsExecuteOn$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsExecuteOn
> = z.nativeEnum(CreatePromptPromptsExecuteOn);

/** @internal */
export const CreatePromptPromptsGuardrails$inboundSchema: z.ZodType<
  CreatePromptPromptsGuardrails,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.union([CreatePromptIdPrompts1$inboundSchema, z.string()]),
  execute_on: CreatePromptPromptsExecuteOn$inboundSchema,
}).transform((v) => {
  return remap$(v, {
    "execute_on": "executeOn",
  });
});

export function createPromptPromptsGuardrailsFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsGuardrails, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsGuardrails$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsGuardrails' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsFallbacks$inboundSchema: z.ZodType<
  CreatePromptPromptsFallbacks,
  z.ZodTypeDef,
  unknown
> = z.object({
  model: z.string(),
});

export function createPromptPromptsFallbacksFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsFallbacks, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsFallbacks$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsFallbacks' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsRetry$inboundSchema: z.ZodType<
  CreatePromptPromptsRetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  count: z.number().default(3),
  on_codes: z.array(z.number()).optional(),
}).transform((v) => {
  return remap$(v, {
    "on_codes": "onCodes",
  });
});

export function createPromptPromptsRetryFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsRetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsRetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsRetry' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsResponseType$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsResponseType
> = z.nativeEnum(CreatePromptPromptsResponseType);

/** @internal */
export const CreatePromptPromptsCache$inboundSchema: z.ZodType<
  CreatePromptPromptsCache,
  z.ZodTypeDef,
  unknown
> = z.object({
  ttl: z.number().default(1800),
  type: CreatePromptPromptsResponseType$inboundSchema,
});

export function createPromptPromptsCacheFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsCache, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsCache$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsCache' from JSON`,
  );
}

/** @internal */
export const CreatePromptLoadBalancerPromptsType$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptLoadBalancerPromptsType
> = z.nativeEnum(CreatePromptLoadBalancerPromptsType);

/** @internal */
export const CreatePromptLoadBalancerPrompts1$inboundSchema: z.ZodType<
  CreatePromptLoadBalancerPrompts1,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: CreatePromptLoadBalancerPromptsType$inboundSchema,
  model: z.string(),
  weight: z.number().default(0.5),
});

export function createPromptLoadBalancerPrompts1FromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptLoadBalancerPrompts1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptLoadBalancerPrompts1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptLoadBalancerPrompts1' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsLoadBalancer$inboundSchema: z.ZodType<
  CreatePromptPromptsLoadBalancer,
  z.ZodTypeDef,
  unknown
> = z.lazy(() => CreatePromptLoadBalancerPrompts1$inboundSchema);

export function createPromptPromptsLoadBalancerFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsLoadBalancer, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsLoadBalancer$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsLoadBalancer' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsTimeout$inboundSchema: z.ZodType<
  CreatePromptPromptsTimeout,
  z.ZodTypeDef,
  unknown
> = z.object({
  call_timeout: z.number(),
}).transform((v) => {
  return remap$(v, {
    "call_timeout": "callTimeout",
  });
});

export function createPromptPromptsTimeoutFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsTimeout, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsTimeout$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsTimeout' from JSON`,
  );
}

/** @internal */
export const CreatePromptContentPromptsResponse200ApplicationJSONResponseBody2$inboundSchema:
  z.ZodType<
    CreatePromptContentPromptsResponse200ApplicationJSONResponseBody2,
    z.ZodTypeDef,
    unknown
  > = components.TextContentPartSchema$inboundSchema;

export function createPromptContentPromptsResponse200ApplicationJSONResponseBody2FromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptContentPromptsResponse200ApplicationJSONResponseBody2,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptContentPromptsResponse200ApplicationJSONResponseBody2$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptContentPromptsResponse200ApplicationJSONResponseBody2' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsResponse200ApplicationJSONResponseBodyContent$inboundSchema:
  z.ZodType<
    CreatePromptMessagesPromptsResponse200ApplicationJSONResponseBodyContent,
    z.ZodTypeDef,
    unknown
  > = z.union([
    z.string(),
    z.array(components.TextContentPartSchema$inboundSchema),
  ]);

export function createPromptMessagesPromptsResponse200ApplicationJSONResponseBodyContentFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptMessagesPromptsResponse200ApplicationJSONResponseBodyContent,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsResponse200ApplicationJSONResponseBodyContent$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptMessagesPromptsResponse200ApplicationJSONResponseBodyContent' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsResponse200Type$inboundSchema:
  z.ZodNativeEnum<typeof CreatePromptMessagesPromptsResponse200Type> = z
    .nativeEnum(CreatePromptMessagesPromptsResponse200Type);

/** @internal */
export const CreatePromptMessagesPromptsTtl$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptMessagesPromptsTtl
> = z.nativeEnum(CreatePromptMessagesPromptsTtl);

/** @internal */
export const CreatePromptMessagesPromptsCacheControl$inboundSchema: z.ZodType<
  CreatePromptMessagesPromptsCacheControl,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: CreatePromptMessagesPromptsResponse200Type$inboundSchema,
  ttl: CreatePromptMessagesPromptsTtl$inboundSchema.default("5m"),
});

export function createPromptMessagesPromptsCacheControlFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptMessagesPromptsCacheControl,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsCacheControl$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptMessagesPromptsCacheControl' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsToolMessage$inboundSchema: z.ZodType<
  CreatePromptMessagesPromptsToolMessage,
  z.ZodTypeDef,
  unknown
> = z.object({
  role: z.literal("tool"),
  content: z.union([
    z.string(),
    z.array(components.TextContentPartSchema$inboundSchema),
  ]),
  tool_call_id: z.nullable(z.string()),
  cache_control: z.lazy(() =>
    CreatePromptMessagesPromptsCacheControl$inboundSchema
  ).optional(),
}).transform((v) => {
  return remap$(v, {
    "tool_call_id": "toolCallId",
    "cache_control": "cacheControl",
  });
});

export function createPromptMessagesPromptsToolMessageFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptMessagesPromptsToolMessage, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsToolMessage$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptMessagesPromptsToolMessage' from JSON`,
  );
}

/** @internal */
export const CreatePromptContentPromptsResponse200ApplicationJson2$inboundSchema:
  z.ZodType<
    CreatePromptContentPromptsResponse200ApplicationJson2,
    z.ZodTypeDef,
    unknown
  > = z.union([
    components.TextContentPartSchema$inboundSchema.and(
      z.object({ type: z.literal("text") }),
    ),
    components.RefusalPartSchema$inboundSchema,
    components.ReasoningPartSchema$inboundSchema,
    components.RedactedReasoningPartSchema$inboundSchema,
  ]);

export function createPromptContentPromptsResponse200ApplicationJSON2FromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptContentPromptsResponse200ApplicationJson2,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptContentPromptsResponse200ApplicationJson2$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptContentPromptsResponse200ApplicationJson2' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsResponse200ApplicationJSONContent$inboundSchema:
  z.ZodType<
    CreatePromptMessagesPromptsResponse200ApplicationJSONContent,
    z.ZodTypeDef,
    unknown
  > = z.union([
    z.string(),
    z.array(
      z.union([
        components.TextContentPartSchema$inboundSchema.and(
          z.object({ type: z.literal("text") }),
        ),
        components.RefusalPartSchema$inboundSchema,
        components.ReasoningPartSchema$inboundSchema,
        components.RedactedReasoningPartSchema$inboundSchema,
      ]),
    ),
  ]);

export function createPromptMessagesPromptsResponse200ApplicationJSONContentFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptMessagesPromptsResponse200ApplicationJSONContent,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsResponse200ApplicationJSONContent$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptMessagesPromptsResponse200ApplicationJSONContent' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsAudio$inboundSchema: z.ZodType<
  CreatePromptMessagesPromptsAudio,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string(),
});

export function createPromptMessagesPromptsAudioFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptMessagesPromptsAudio, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptMessagesPromptsAudio$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptMessagesPromptsAudio' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsResponseType$inboundSchema:
  z.ZodNativeEnum<typeof CreatePromptMessagesPromptsResponseType> = z
    .nativeEnum(CreatePromptMessagesPromptsResponseType);

/** @internal */
export const CreatePromptMessagesPromptsFunction$inboundSchema: z.ZodType<
  CreatePromptMessagesPromptsFunction,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  arguments: z.string().optional(),
});

export function createPromptMessagesPromptsFunctionFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptMessagesPromptsFunction, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsFunction$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptMessagesPromptsFunction' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsToolCalls$inboundSchema: z.ZodType<
  CreatePromptMessagesPromptsToolCalls,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string(),
  type: CreatePromptMessagesPromptsResponseType$inboundSchema,
  function: z.lazy(() => CreatePromptMessagesPromptsFunction$inboundSchema),
  thought_signature: z.string().optional(),
}).transform((v) => {
  return remap$(v, {
    "thought_signature": "thoughtSignature",
  });
});

export function createPromptMessagesPromptsToolCallsFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptMessagesPromptsToolCalls, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsToolCalls$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptMessagesPromptsToolCalls' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsAssistantMessage$inboundSchema:
  z.ZodType<
    CreatePromptMessagesPromptsAssistantMessage,
    z.ZodTypeDef,
    unknown
  > = z.object({
    content: z.nullable(
      z.union([
        z.string(),
        z.array(
          z.union([
            components.TextContentPartSchema$inboundSchema.and(
              z.object({ type: z.literal("text") }),
            ),
            components.RefusalPartSchema$inboundSchema,
            components.ReasoningPartSchema$inboundSchema,
            components.RedactedReasoningPartSchema$inboundSchema,
          ]),
        ),
      ]),
    ).optional(),
    refusal: z.nullable(z.string()).optional(),
    role: z.literal("assistant"),
    name: z.string().optional(),
    audio: z.nullable(
      z.lazy(() => CreatePromptMessagesPromptsAudio$inboundSchema),
    ).optional(),
    tool_calls: z.array(
      z.lazy(() => CreatePromptMessagesPromptsToolCalls$inboundSchema),
    ).optional(),
  }).transform((v) => {
    return remap$(v, {
      "tool_calls": "toolCalls",
    });
  });

export function createPromptMessagesPromptsAssistantMessageFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptMessagesPromptsAssistantMessage,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsAssistantMessage$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptMessagesPromptsAssistantMessage' from JSON`,
  );
}

/** @internal */
export const CreatePrompt2PromptsResponse200ApplicationJSONResponseBodyPromptType$inboundSchema:
  z.ZodNativeEnum<
    typeof CreatePrompt2PromptsResponse200ApplicationJSONResponseBodyPromptType
  > = z.nativeEnum(
    CreatePrompt2PromptsResponse200ApplicationJSONResponseBodyPromptType,
  );

/** @internal */
export const CreatePrompt2PromptsTtl$inboundSchema: z.ZodNativeEnum<
  typeof CreatePrompt2PromptsTtl
> = z.nativeEnum(CreatePrompt2PromptsTtl);

/** @internal */
export const CreatePrompt2PromptsCacheControl$inboundSchema: z.ZodType<
  CreatePrompt2PromptsCacheControl,
  z.ZodTypeDef,
  unknown
> = z.object({
  type:
    CreatePrompt2PromptsResponse200ApplicationJSONResponseBodyPromptType$inboundSchema,
  ttl: CreatePrompt2PromptsTtl$inboundSchema.default("5m"),
});

export function createPrompt2PromptsCacheControlFromJSON(
  jsonString: string,
): SafeParseResult<CreatePrompt2PromptsCacheControl, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePrompt2PromptsCacheControl$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePrompt2PromptsCacheControl' from JSON`,
  );
}

/** @internal */
export const CreatePrompt2Prompts4$inboundSchema: z.ZodType<
  CreatePrompt2Prompts4,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: z.literal("file"),
  cache_control: z.lazy(() => CreatePrompt2PromptsCacheControl$inboundSchema)
    .optional(),
  file: components.FileContentPartSchema$inboundSchema,
}).transform((v) => {
  return remap$(v, {
    "cache_control": "cacheControl",
  });
});

export function createPrompt2Prompts4FromJSON(
  jsonString: string,
): SafeParseResult<CreatePrompt2Prompts4, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePrompt2Prompts4$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePrompt2Prompts4' from JSON`,
  );
}

/** @internal */
export const CreatePromptContentPromptsResponse2002$inboundSchema: z.ZodType<
  CreatePromptContentPromptsResponse2002,
  z.ZodTypeDef,
  unknown
> = z.union([
  components.TextContentPartSchema$inboundSchema.and(
    z.object({ type: z.literal("text") }),
  ),
  components.ImageContentPartSchema$inboundSchema,
  components.AudioContentPartSchema$inboundSchema,
  z.lazy(() => CreatePrompt2Prompts4$inboundSchema),
]);

export function createPromptContentPromptsResponse2002FromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptContentPromptsResponse2002, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptContentPromptsResponse2002$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptContentPromptsResponse2002' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsResponse200Content$inboundSchema:
  z.ZodType<
    CreatePromptMessagesPromptsResponse200Content,
    z.ZodTypeDef,
    unknown
  > = z.union([
    z.string(),
    z.array(
      z.union([
        components.TextContentPartSchema$inboundSchema.and(
          z.object({ type: z.literal("text") }),
        ),
        components.ImageContentPartSchema$inboundSchema,
        components.AudioContentPartSchema$inboundSchema,
        z.lazy(() => CreatePrompt2Prompts4$inboundSchema),
      ]),
    ),
  ]);

export function createPromptMessagesPromptsResponse200ContentFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptMessagesPromptsResponse200Content,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsResponse200Content$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptMessagesPromptsResponse200Content' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsUserMessage$inboundSchema: z.ZodType<
  CreatePromptMessagesPromptsUserMessage,
  z.ZodTypeDef,
  unknown
> = z.object({
  role: z.literal("user"),
  name: z.string().optional(),
  content: z.union([
    z.string(),
    z.array(
      z.union([
        components.TextContentPartSchema$inboundSchema.and(
          z.object({ type: z.literal("text") }),
        ),
        components.ImageContentPartSchema$inboundSchema,
        components.AudioContentPartSchema$inboundSchema,
        z.lazy(() => CreatePrompt2Prompts4$inboundSchema),
      ]),
    ),
  ]),
});

export function createPromptMessagesPromptsUserMessageFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptMessagesPromptsUserMessage, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsUserMessage$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptMessagesPromptsUserMessage' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsResponseContent$inboundSchema:
  z.ZodType<CreatePromptMessagesPromptsResponseContent, z.ZodTypeDef, unknown> =
    z.union([
      z.string(),
      z.array(components.TextContentPartSchema$inboundSchema),
    ]);

export function createPromptMessagesPromptsResponseContentFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptMessagesPromptsResponseContent,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsResponseContent$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptMessagesPromptsResponseContent' from JSON`,
  );
}

/** @internal */
export const CreatePromptMessagesPromptsSystemMessage$inboundSchema: z.ZodType<
  CreatePromptMessagesPromptsSystemMessage,
  z.ZodTypeDef,
  unknown
> = z.object({
  role: z.literal("system"),
  content: z.union([
    z.string(),
    z.array(components.TextContentPartSchema$inboundSchema),
  ]),
  name: z.string().optional(),
});

export function createPromptMessagesPromptsSystemMessageFromJSON(
  jsonString: string,
): SafeParseResult<
  CreatePromptMessagesPromptsSystemMessage,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptMessagesPromptsSystemMessage$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'CreatePromptMessagesPromptsSystemMessage' from JSON`,
  );
}

/** @internal */
export const CreatePromptPromptsResponseMessages$inboundSchema: z.ZodType<
  CreatePromptPromptsResponseMessages,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => CreatePromptMessagesPromptsSystemMessage$inboundSchema),
  z.lazy(() => CreatePromptMessagesPromptsUserMessage$inboundSchema),
  z.lazy(() => CreatePromptMessagesPromptsAssistantMessage$inboundSchema),
  z.lazy(() => CreatePromptMessagesPromptsToolMessage$inboundSchema),
]);

export function createPromptPromptsResponseMessagesFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsResponseMessages, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      CreatePromptPromptsResponseMessages$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsResponseMessages' from JSON`,
  );
}

/** @internal */
export const PromptField$inboundSchema: z.ZodType<
  PromptField,
  z.ZodTypeDef,
  unknown
> = z.object({
  audio: z.nullable(z.lazy(() => CreatePromptPromptsAudio$inboundSchema))
    .optional(),
  frequency_penalty: z.nullable(z.number()).optional(),
  max_tokens: z.nullable(z.number().int()).optional(),
  max_completion_tokens: z.nullable(z.number().int()).optional(),
  logprobs: z.nullable(z.boolean()).optional(),
  top_logprobs: z.nullable(z.number().int()).optional(),
  n: z.nullable(z.number().int()).optional(),
  presence_penalty: z.nullable(z.number()).optional(),
  response_format: z.union([
    z.lazy(() => CreatePromptResponseFormatPromptsText$inboundSchema),
    z.lazy(() => CreatePromptResponseFormatPromptsJSONObject$inboundSchema),
    z.lazy(() =>
      CreatePromptResponseFormatPromptsResponse200JSONSchema$inboundSchema
    ),
  ]).optional(),
  reasoning_effort: CreatePromptPromptsReasoningEffort$inboundSchema.optional(),
  verbosity: z.string().optional(),
  seed: z.nullable(z.number()).optional(),
  stop: z.nullable(z.union([z.string(), z.array(z.string())])).optional(),
  stream_options: z.nullable(
    z.lazy(() => CreatePromptPromptsStreamOptions$inboundSchema),
  ).optional(),
  thinking: z.union([
    components.ThinkingConfigDisabledSchema$inboundSchema,
    components.ThinkingConfigEnabledSchema$inboundSchema,
  ]).optional(),
  temperature: z.nullable(z.number()).optional(),
  top_p: z.nullable(z.number()).optional(),
  top_k: z.nullable(z.number()).optional(),
  tool_choice: z.union([
    z.lazy(() => CreatePromptToolChoicePrompts2$inboundSchema),
    CreatePromptToolChoicePrompts1$inboundSchema,
  ]).optional(),
  parallel_tool_calls: z.boolean().optional(),
  modalities: z.nullable(z.array(CreatePromptPromptsModalities$inboundSchema))
    .optional(),
  guardrails: z.array(z.lazy(() => CreatePromptPromptsGuardrails$inboundSchema))
    .optional(),
  fallbacks: z.array(z.lazy(() => CreatePromptPromptsFallbacks$inboundSchema))
    .optional(),
  retry: z.lazy(() => CreatePromptPromptsRetry$inboundSchema).optional(),
  cache: z.lazy(() => CreatePromptPromptsCache$inboundSchema).optional(),
  load_balancer: z.array(
    z.lazy(() => CreatePromptLoadBalancerPrompts1$inboundSchema),
  ).optional(),
  timeout: z.lazy(() => CreatePromptPromptsTimeout$inboundSchema).optional(),
  messages: z.array(
    z.union([
      z.lazy(() => CreatePromptMessagesPromptsSystemMessage$inboundSchema),
      z.lazy(() => CreatePromptMessagesPromptsUserMessage$inboundSchema),
      z.lazy(() => CreatePromptMessagesPromptsAssistantMessage$inboundSchema),
      z.lazy(() => CreatePromptMessagesPromptsToolMessage$inboundSchema),
    ]),
  ).optional(),
  model: z.nullable(z.string()).optional(),
  version: z.string().optional(),
}).transform((v) => {
  return remap$(v, {
    "frequency_penalty": "frequencyPenalty",
    "max_tokens": "maxTokens",
    "max_completion_tokens": "maxCompletionTokens",
    "top_logprobs": "topLogprobs",
    "presence_penalty": "presencePenalty",
    "response_format": "responseFormat",
    "reasoning_effort": "reasoningEffort",
    "stream_options": "streamOptions",
    "top_p": "topP",
    "top_k": "topK",
    "tool_choice": "toolChoice",
    "parallel_tool_calls": "parallelToolCalls",
    "load_balancer": "loadBalancer",
  });
});

export function promptFieldFromJSON(
  jsonString: string,
): SafeParseResult<PromptField, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PromptField$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PromptField' from JSON`,
  );
}

/** @internal */
export const CreatePromptUseCases$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptUseCases
> = z.nativeEnum(CreatePromptUseCases);

/** @internal */
export const CreatePromptPromptsLanguage$inboundSchema: z.ZodNativeEnum<
  typeof CreatePromptPromptsLanguage
> = z.nativeEnum(CreatePromptPromptsLanguage);

/** @internal */
export const CreatePromptPromptsMetadata$inboundSchema: z.ZodType<
  CreatePromptPromptsMetadata,
  z.ZodTypeDef,
  unknown
> = z.object({
  use_cases: z.array(CreatePromptUseCases$inboundSchema).optional(),
  language: z.nullable(CreatePromptPromptsLanguage$inboundSchema).optional(),
}).transform((v) => {
  return remap$(v, {
    "use_cases": "useCases",
  });
});

export function createPromptPromptsMetadataFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPromptsMetadata, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPromptsMetadata$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPromptsMetadata' from JSON`,
  );
}

/** @internal */
export const CreatePromptPrompt$inboundSchema: z.ZodType<
  CreatePromptPrompt,
  z.ZodTypeDef,
  unknown
> = z.object({
  _id: z.string(),
  type: CreatePromptPromptsType$inboundSchema,
  owner: z.string(),
  domain_id: z.string(),
  created: z.string(),
  updated: z.string(),
  created_by_id: z.nullable(z.string()).optional(),
  updated_by_id: z.nullable(z.string()).optional(),
  display_name: z.string(),
  description: z.nullable(z.string()).optional(),
  prompt_config: z.lazy(() => PromptConfig$inboundSchema).optional(),
  prompt: z.lazy(() => PromptField$inboundSchema),
  metadata: z.lazy(() => CreatePromptPromptsMetadata$inboundSchema).optional(),
}).transform((v) => {
  return remap$(v, {
    "_id": "id",
    "domain_id": "domainId",
    "created_by_id": "createdById",
    "updated_by_id": "updatedById",
    "display_name": "displayName",
    "prompt_config": "promptConfig",
  });
});

export function createPromptPromptFromJSON(
  jsonString: string,
): SafeParseResult<CreatePromptPrompt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreatePromptPrompt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreatePromptPrompt' from JSON`,
  );
}
