# PromptInput

Prompt configuration with model and messages. Either this field or `prompt_config` must be provided.

## Example Usage

```typescript
import { PromptInput } from "@orq-ai/node/models/operations";

let value: PromptInput = {
  messages: [
    {
      role: "system",
      content: "You are a helpful assistant",
    },
    {
      role: "user",
      content: "What is the weather today?",
    },
  ],
  model: "openai/gpt-4o",
  temperature: 0.7,
  maxTokens: 1000,
};
```

## Fields

| Field                                                                                                                                                                                                                                                                              | Type                                                                                                                                                                                                                                                                               | Required                                                                                                                                                                                                                                                                           | Description                                                                                                                                                                                                                                                                        | Example                                                                                                                                                                                                                                                                            |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `messages`                                                                                                                                                                                                                                                                         | *operations.CreatePromptPromptsMessages*[]                                                                                                                                                                                                                                         | :heavy_check_mark:                                                                                                                                                                                                                                                                 | Array of messages that make up the conversation. Each message has a role (system, user, assistant, or tool) and content.                                                                                                                                                           | [<br/>{<br/>"role": "system",<br/>"content": "You are a helpful assistant"<br/>},<br/>{<br/>"role": "user",<br/>"content": "What is the weather today?"<br/>}<br/>]                                                                                                                |
| `model`                                                                                                                                                                                                                                                                            | *string*                                                                                                                                                                                                                                                                           | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | Model ID used to generate the response, like `openai/gpt-4o` or `anthropic/claude-3-5-sonnet-20241022`. The full list of models can be found at https://docs.orq.ai/docs/ai-gateway-supported-models. Only chat models are supported.                                              | openai/gpt-4o                                                                                                                                                                                                                                                                      |
| `temperature`                                                                                                                                                                                                                                                                      | *number*                                                                                                                                                                                                                                                                           | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.                                                                                               |                                                                                                                                                                                                                                                                                    |
| `maxTokens`                                                                                                                                                                                                                                                                        | *number*                                                                                                                                                                                                                                                                           | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | `[Deprecated]`. The maximum number of tokens that can be generated in the chat completion. This value can be used to control costs for text generated via API. <br/><br/> This value is now `deprecated` in favor of `max_completion_tokens`, and is not compatible with o1 series models. |                                                                                                                                                                                                                                                                                    |
| `responseFormat`                                                                                                                                                                                                                                                                   | *operations.CreatePromptPromptsResponseFormat*                                                                                                                                                                                                                                     | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | An object specifying the format that the model must output                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                    |